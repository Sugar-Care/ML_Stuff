{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "vvm3yurhVZO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hU5cl5pvhypL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Split Dataset"
      ],
      "metadata": {
        "id": "LfpRnzN2Vdnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Capstone Project/dataset/dataset_cleaned.csv')"
      ],
      "metadata": {
        "id": "Moy8bdBBkSVm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Age', 'Blood Glucose Levels', 'Blood Pressure', 'Weight Gain During Pregnancy',\n",
        "        'Waist Circumference', 'BMI', 'Insulin Levels', 'Cholesterol Levels',\n",
        "        'Digestive Enzyme Levels', 'Pulmonary Function']]\n",
        "y = df['Target']\n",
        "\n",
        "# Split data into training and temporary sets (80% train, 20% temp)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42) #random_state for reproducibility\n",
        "\n",
        "# Split the temporary set into validation and testing sets (50% validation, 50% test)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Now you have:\n",
        "print(len(X_train), len(y_train))\n",
        "print(len(X_val), len(y_val))\n",
        "print(len(X_test), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqkFDkUG5FoA",
        "outputId": "37558582-57b0-4cfb-de4e-ef58a1196aa4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16354 16354\n",
            "2044 2044\n",
            "2045 2045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "RY1P-EdZKPTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ],
      "metadata": {
        "id": "RIzWgBC0Kdnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sulthan =  tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Conv1D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(len(df['Target'].unique()), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydf8pPwhVXKd",
        "outputId": "ce3d9d4e-2a6e-474d-e0a1-5ed1000e8e97"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sulthan.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mae', 'mse'])\n",
        "sulthan.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "gXIyfSFe8e8X",
        "outputId": "414a88bc-8c85-45c3-b30e-6cb514e5992c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m6,208\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  │           \u001b[38;5;34m1,677\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,333\u001b[0m (63.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,333</span> (63.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,333\u001b[0m (63.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,333</span> (63.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "snIP6kgkKgrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = sulthan.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksaEcvYG9B-M",
        "outputId": "a7445c20-f8d6-40de-b66d-8da528b3251a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2219 - loss: 3.9694 - mae: 5.9641 - mse: 49.4420 - val_accuracy: 0.5582 - val_loss: 1.2004 - val_mae: 5.9226 - val_mse: 48.9581\n",
            "Epoch 2/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5325 - loss: 1.2657 - mae: 5.9736 - mse: 49.4894 - val_accuracy: 0.6477 - val_loss: 0.9228 - val_mae: 5.9226 - val_mse: 48.9666\n",
            "Epoch 3/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6116 - loss: 1.0103 - mae: 5.9201 - mse: 49.0075 - val_accuracy: 0.6644 - val_loss: 0.8419 - val_mae: 5.9226 - val_mse: 48.9704\n",
            "Epoch 4/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6394 - loss: 0.9097 - mae: 5.9761 - mse: 49.8638 - val_accuracy: 0.6766 - val_loss: 0.7823 - val_mae: 5.9226 - val_mse: 48.9735\n",
            "Epoch 5/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6504 - loss: 0.8708 - mae: 5.9629 - mse: 49.8094 - val_accuracy: 0.7040 - val_loss: 0.7537 - val_mae: 5.9226 - val_mse: 48.9747\n",
            "Epoch 6/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6676 - loss: 0.8256 - mae: 5.8978 - mse: 48.8683 - val_accuracy: 0.6957 - val_loss: 0.7547 - val_mae: 5.9226 - val_mse: 48.9773\n",
            "Epoch 7/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6822 - loss: 0.7962 - mae: 5.9783 - mse: 49.8659 - val_accuracy: 0.7030 - val_loss: 0.7312 - val_mae: 5.9226 - val_mse: 48.9765\n",
            "Epoch 8/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6733 - loss: 0.7920 - mae: 5.9309 - mse: 49.3250 - val_accuracy: 0.7128 - val_loss: 0.7062 - val_mae: 5.9226 - val_mse: 48.9770\n",
            "Epoch 9/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6788 - loss: 0.7878 - mae: 5.9227 - mse: 48.9580 - val_accuracy: 0.7060 - val_loss: 0.7208 - val_mae: 5.9226 - val_mse: 48.9789\n",
            "Epoch 10/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6909 - loss: 0.7586 - mae: 6.0194 - mse: 50.3382 - val_accuracy: 0.7192 - val_loss: 0.7017 - val_mae: 5.9226 - val_mse: 48.9773\n",
            "Epoch 11/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6932 - loss: 0.7633 - mae: 5.9423 - mse: 49.3764 - val_accuracy: 0.7167 - val_loss: 0.6803 - val_mae: 5.9226 - val_mse: 48.9784\n",
            "Epoch 12/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6894 - loss: 0.7540 - mae: 5.9527 - mse: 49.5162 - val_accuracy: 0.6776 - val_loss: 0.7883 - val_mae: 5.9226 - val_mse: 48.9779\n",
            "Epoch 13/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7012 - loss: 0.7373 - mae: 5.9815 - mse: 49.7723 - val_accuracy: 0.7187 - val_loss: 0.6786 - val_mae: 5.9226 - val_mse: 48.9804\n",
            "Epoch 14/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7034 - loss: 0.7184 - mae: 5.9833 - mse: 49.6820 - val_accuracy: 0.7270 - val_loss: 0.6618 - val_mae: 5.9226 - val_mse: 48.9793\n",
            "Epoch 15/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7032 - loss: 0.7151 - mae: 5.9130 - mse: 48.9910 - val_accuracy: 0.7114 - val_loss: 0.7095 - val_mae: 5.9226 - val_mse: 48.9789\n",
            "Epoch 16/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7116 - loss: 0.7085 - mae: 5.9525 - mse: 49.4391 - val_accuracy: 0.7314 - val_loss: 0.6453 - val_mae: 5.9226 - val_mse: 48.9814\n",
            "Epoch 17/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7147 - loss: 0.7077 - mae: 5.9402 - mse: 49.2747 - val_accuracy: 0.7285 - val_loss: 0.6923 - val_mae: 5.9226 - val_mse: 48.9799\n",
            "Epoch 18/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7191 - loss: 0.6886 - mae: 5.9629 - mse: 49.4989 - val_accuracy: 0.7441 - val_loss: 0.6236 - val_mae: 5.9226 - val_mse: 48.9813\n",
            "Epoch 19/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7145 - loss: 0.6883 - mae: 5.9023 - mse: 48.9025 - val_accuracy: 0.7363 - val_loss: 0.6467 - val_mae: 5.9226 - val_mse: 48.9815\n",
            "Epoch 20/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7194 - loss: 0.6741 - mae: 5.9438 - mse: 49.4506 - val_accuracy: 0.7285 - val_loss: 0.6593 - val_mae: 5.9226 - val_mse: 48.9809\n",
            "Epoch 21/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7175 - loss: 0.6952 - mae: 5.9780 - mse: 49.8034 - val_accuracy: 0.7290 - val_loss: 0.6611 - val_mae: 5.9226 - val_mse: 48.9816\n",
            "Epoch 22/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.7240 - loss: 0.6787 - mae: 5.9417 - mse: 49.4027 - val_accuracy: 0.7510 - val_loss: 0.6180 - val_mae: 5.9226 - val_mse: 48.9831\n",
            "Epoch 23/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7239 - loss: 0.6711 - mae: 5.9572 - mse: 49.6088 - val_accuracy: 0.7490 - val_loss: 0.6183 - val_mae: 5.9226 - val_mse: 48.9817\n",
            "Epoch 24/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7337 - loss: 0.6540 - mae: 5.9766 - mse: 49.7794 - val_accuracy: 0.7324 - val_loss: 0.6547 - val_mae: 5.9226 - val_mse: 48.9799\n",
            "Epoch 25/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7315 - loss: 0.6455 - mae: 5.9725 - mse: 49.6547 - val_accuracy: 0.7495 - val_loss: 0.6295 - val_mae: 5.9226 - val_mse: 48.9819\n",
            "Epoch 26/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7321 - loss: 0.6479 - mae: 5.9646 - mse: 49.7384 - val_accuracy: 0.7480 - val_loss: 0.6096 - val_mae: 5.9226 - val_mse: 48.9834\n",
            "Epoch 27/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7359 - loss: 0.6381 - mae: 5.9586 - mse: 49.5160 - val_accuracy: 0.7422 - val_loss: 0.6257 - val_mae: 5.9226 - val_mse: 48.9819\n",
            "Epoch 28/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7359 - loss: 0.6361 - mae: 5.9338 - mse: 49.1783 - val_accuracy: 0.7505 - val_loss: 0.6067 - val_mae: 5.9226 - val_mse: 48.9833\n",
            "Epoch 29/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7413 - loss: 0.6239 - mae: 5.9453 - mse: 49.4515 - val_accuracy: 0.7495 - val_loss: 0.5924 - val_mae: 5.9226 - val_mse: 48.9836\n",
            "Epoch 30/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7383 - loss: 0.6237 - mae: 5.9456 - mse: 49.4195 - val_accuracy: 0.7485 - val_loss: 0.6119 - val_mae: 5.9226 - val_mse: 48.9839\n",
            "Epoch 31/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7467 - loss: 0.6179 - mae: 5.9322 - mse: 49.2724 - val_accuracy: 0.7549 - val_loss: 0.5839 - val_mae: 5.9226 - val_mse: 48.9848\n",
            "Epoch 32/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7537 - loss: 0.5998 - mae: 5.9864 - mse: 49.9966 - val_accuracy: 0.7476 - val_loss: 0.5989 - val_mae: 5.9226 - val_mse: 48.9827\n",
            "Epoch 33/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7546 - loss: 0.6056 - mae: 5.9660 - mse: 49.7012 - val_accuracy: 0.7500 - val_loss: 0.5811 - val_mae: 5.9226 - val_mse: 48.9821\n",
            "Epoch 34/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7486 - loss: 0.6128 - mae: 5.8900 - mse: 48.6997 - val_accuracy: 0.7495 - val_loss: 0.5935 - val_mae: 5.9226 - val_mse: 48.9849\n",
            "Epoch 35/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7444 - loss: 0.6268 - mae: 5.9569 - mse: 49.6147 - val_accuracy: 0.7671 - val_loss: 0.5812 - val_mae: 5.9226 - val_mse: 48.9833\n",
            "Epoch 36/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7447 - loss: 0.6199 - mae: 5.9309 - mse: 49.3745 - val_accuracy: 0.7529 - val_loss: 0.5931 - val_mae: 5.9226 - val_mse: 48.9836\n",
            "Epoch 37/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7466 - loss: 0.6127 - mae: 5.9209 - mse: 48.9210 - val_accuracy: 0.7750 - val_loss: 0.5452 - val_mae: 5.9226 - val_mse: 48.9842\n",
            "Epoch 38/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.5879 - mae: 5.9497 - mse: 49.4642 - val_accuracy: 0.7544 - val_loss: 0.5833 - val_mae: 5.9226 - val_mse: 48.9832\n",
            "Epoch 39/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7461 - loss: 0.6018 - mae: 5.9736 - mse: 49.8341 - val_accuracy: 0.7568 - val_loss: 0.5652 - val_mae: 5.9226 - val_mse: 48.9847\n",
            "Epoch 40/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7567 - loss: 0.5886 - mae: 5.9396 - mse: 49.3918 - val_accuracy: 0.7622 - val_loss: 0.5654 - val_mae: 5.9226 - val_mse: 48.9857\n",
            "Epoch 41/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7680 - loss: 0.5660 - mae: 5.9446 - mse: 49.4555 - val_accuracy: 0.7745 - val_loss: 0.5484 - val_mae: 5.9226 - val_mse: 48.9848\n",
            "Epoch 42/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7669 - loss: 0.5721 - mae: 5.9725 - mse: 49.6748 - val_accuracy: 0.7691 - val_loss: 0.5529 - val_mae: 5.9226 - val_mse: 48.9857\n",
            "Epoch 43/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7570 - loss: 0.5751 - mae: 5.9402 - mse: 49.3464 - val_accuracy: 0.7657 - val_loss: 0.5534 - val_mae: 5.9226 - val_mse: 48.9853\n",
            "Epoch 44/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7629 - loss: 0.5795 - mae: 5.9110 - mse: 49.0223 - val_accuracy: 0.7705 - val_loss: 0.5384 - val_mae: 5.9226 - val_mse: 48.9860\n",
            "Epoch 45/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7680 - loss: 0.5532 - mae: 5.9414 - mse: 49.3989 - val_accuracy: 0.7813 - val_loss: 0.5372 - val_mae: 5.9226 - val_mse: 48.9857\n",
            "Epoch 46/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7735 - loss: 0.5512 - mae: 5.9316 - mse: 49.2892 - val_accuracy: 0.7627 - val_loss: 0.5757 - val_mae: 5.9226 - val_mse: 48.9833\n",
            "Epoch 47/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7642 - loss: 0.5715 - mae: 5.9028 - mse: 48.8378 - val_accuracy: 0.7798 - val_loss: 0.5387 - val_mae: 5.9226 - val_mse: 48.9849\n",
            "Epoch 48/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7648 - loss: 0.5625 - mae: 5.9420 - mse: 49.4798 - val_accuracy: 0.7583 - val_loss: 0.5587 - val_mae: 5.9226 - val_mse: 48.9866\n",
            "Epoch 49/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7629 - loss: 0.5621 - mae: 5.9046 - mse: 49.0168 - val_accuracy: 0.7813 - val_loss: 0.5325 - val_mae: 5.9226 - val_mse: 48.9877\n",
            "Epoch 50/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7721 - loss: 0.5433 - mae: 5.9267 - mse: 49.2901 - val_accuracy: 0.7691 - val_loss: 0.5580 - val_mae: 5.9226 - val_mse: 48.9853\n",
            "Epoch 51/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7615 - loss: 0.5568 - mae: 5.9519 - mse: 49.5909 - val_accuracy: 0.7588 - val_loss: 0.5631 - val_mae: 5.9226 - val_mse: 48.9872\n",
            "Epoch 52/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7638 - loss: 0.5666 - mae: 5.9204 - mse: 49.2411 - val_accuracy: 0.7657 - val_loss: 0.5599 - val_mae: 5.9226 - val_mse: 48.9858\n",
            "Epoch 53/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.5435 - mae: 5.9268 - mse: 49.2958 - val_accuracy: 0.7784 - val_loss: 0.5216 - val_mae: 5.9226 - val_mse: 48.9866\n",
            "Epoch 54/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7679 - loss: 0.5531 - mae: 5.9863 - mse: 50.0400 - val_accuracy: 0.7803 - val_loss: 0.5091 - val_mae: 5.9226 - val_mse: 48.9877\n",
            "Epoch 55/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7779 - loss: 0.5365 - mae: 5.9107 - mse: 48.9116 - val_accuracy: 0.7769 - val_loss: 0.5319 - val_mae: 5.9226 - val_mse: 48.9858\n",
            "Epoch 56/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7747 - loss: 0.5329 - mae: 5.8839 - mse: 48.6508 - val_accuracy: 0.7833 - val_loss: 0.5191 - val_mae: 5.9226 - val_mse: 48.9867\n",
            "Epoch 57/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7808 - loss: 0.5265 - mae: 5.9544 - mse: 49.5751 - val_accuracy: 0.7588 - val_loss: 0.5660 - val_mae: 5.9226 - val_mse: 48.9861\n",
            "Epoch 58/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.5245 - mae: 5.9575 - mse: 49.5932 - val_accuracy: 0.7911 - val_loss: 0.5003 - val_mae: 5.9226 - val_mse: 48.9863\n",
            "Epoch 59/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 0.5268 - mae: 5.8997 - mse: 49.0604 - val_accuracy: 0.7857 - val_loss: 0.5186 - val_mae: 5.9226 - val_mse: 48.9877\n",
            "Epoch 60/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7707 - loss: 0.5425 - mae: 5.9497 - mse: 49.6581 - val_accuracy: 0.7671 - val_loss: 0.5491 - val_mae: 5.9226 - val_mse: 48.9868\n",
            "Epoch 61/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7820 - loss: 0.5169 - mae: 5.9456 - mse: 49.5005 - val_accuracy: 0.7666 - val_loss: 0.5365 - val_mae: 5.9226 - val_mse: 48.9866\n",
            "Epoch 62/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7842 - loss: 0.5186 - mae: 5.9448 - mse: 49.3771 - val_accuracy: 0.7833 - val_loss: 0.5125 - val_mae: 5.9226 - val_mse: 48.9870\n",
            "Epoch 63/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7849 - loss: 0.5100 - mae: 5.9323 - mse: 49.1793 - val_accuracy: 0.7862 - val_loss: 0.5064 - val_mae: 5.9226 - val_mse: 48.9880\n",
            "Epoch 64/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7891 - loss: 0.5091 - mae: 5.8991 - mse: 48.8780 - val_accuracy: 0.7735 - val_loss: 0.5370 - val_mae: 5.9226 - val_mse: 48.9862\n",
            "Epoch 65/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7752 - loss: 0.5312 - mae: 5.9321 - mse: 49.2775 - val_accuracy: 0.7857 - val_loss: 0.4952 - val_mae: 5.9226 - val_mse: 48.9876\n",
            "Epoch 66/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7850 - loss: 0.5089 - mae: 5.9414 - mse: 49.4254 - val_accuracy: 0.7847 - val_loss: 0.5292 - val_mae: 5.9226 - val_mse: 48.9864\n",
            "Epoch 67/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7897 - loss: 0.5049 - mae: 5.9222 - mse: 49.2044 - val_accuracy: 0.7730 - val_loss: 0.5320 - val_mae: 5.9226 - val_mse: 48.9892\n",
            "Epoch 68/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7874 - loss: 0.5079 - mae: 5.9789 - mse: 49.7410 - val_accuracy: 0.7931 - val_loss: 0.4830 - val_mae: 5.9226 - val_mse: 48.9873\n",
            "Epoch 69/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7924 - loss: 0.4903 - mae: 5.9546 - mse: 49.5545 - val_accuracy: 0.7681 - val_loss: 0.5477 - val_mae: 5.9226 - val_mse: 48.9873\n",
            "Epoch 70/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7862 - loss: 0.5065 - mae: 5.9026 - mse: 48.8798 - val_accuracy: 0.7818 - val_loss: 0.5243 - val_mae: 5.9226 - val_mse: 48.9868\n",
            "Epoch 71/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7905 - loss: 0.4991 - mae: 5.8908 - mse: 48.7118 - val_accuracy: 0.7935 - val_loss: 0.4928 - val_mae: 5.9226 - val_mse: 48.9884\n",
            "Epoch 72/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7956 - loss: 0.4782 - mae: 5.9092 - mse: 48.9613 - val_accuracy: 0.7857 - val_loss: 0.4978 - val_mae: 5.9226 - val_mse: 48.9891\n",
            "Epoch 73/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.5172 - mae: 5.9970 - mse: 50.1358 - val_accuracy: 0.7935 - val_loss: 0.5206 - val_mae: 5.9226 - val_mse: 48.9901\n",
            "Epoch 74/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7918 - loss: 0.4890 - mae: 5.9661 - mse: 49.7409 - val_accuracy: 0.7779 - val_loss: 0.5322 - val_mae: 5.9226 - val_mse: 48.9879\n",
            "Epoch 75/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7936 - loss: 0.4880 - mae: 5.9866 - mse: 49.8686 - val_accuracy: 0.7901 - val_loss: 0.4859 - val_mae: 5.9226 - val_mse: 48.9897\n",
            "Epoch 76/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7941 - loss: 0.4903 - mae: 5.9107 - mse: 48.9266 - val_accuracy: 0.7886 - val_loss: 0.5018 - val_mae: 5.9226 - val_mse: 48.9881\n",
            "Epoch 77/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7905 - loss: 0.4978 - mae: 5.9057 - mse: 48.8863 - val_accuracy: 0.7999 - val_loss: 0.4752 - val_mae: 5.9226 - val_mse: 48.9878\n",
            "Epoch 78/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7889 - loss: 0.5002 - mae: 5.9303 - mse: 49.1921 - val_accuracy: 0.8014 - val_loss: 0.4732 - val_mae: 5.9226 - val_mse: 48.9883\n",
            "Epoch 79/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7929 - loss: 0.4948 - mae: 5.9346 - mse: 49.2831 - val_accuracy: 0.7877 - val_loss: 0.4872 - val_mae: 5.9226 - val_mse: 48.9880\n",
            "Epoch 80/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7908 - loss: 0.4897 - mae: 5.9096 - mse: 48.9065 - val_accuracy: 0.7774 - val_loss: 0.5208 - val_mae: 5.9226 - val_mse: 48.9888\n",
            "Epoch 81/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7862 - loss: 0.4997 - mae: 5.9413 - mse: 49.3674 - val_accuracy: 0.7490 - val_loss: 0.6202 - val_mae: 5.9226 - val_mse: 48.9864\n",
            "Epoch 82/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.5007 - mae: 5.9211 - mse: 49.1078 - val_accuracy: 0.7994 - val_loss: 0.4630 - val_mae: 5.9226 - val_mse: 48.9883\n",
            "Epoch 83/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8058 - loss: 0.4693 - mae: 5.9412 - mse: 49.5452 - val_accuracy: 0.7979 - val_loss: 0.4684 - val_mae: 5.9226 - val_mse: 48.9889\n",
            "Epoch 84/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4723 - mae: 5.9719 - mse: 49.8744 - val_accuracy: 0.8019 - val_loss: 0.4734 - val_mae: 5.9226 - val_mse: 48.9886\n",
            "Epoch 85/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7915 - loss: 0.4827 - mae: 5.9083 - mse: 48.9329 - val_accuracy: 0.7867 - val_loss: 0.4887 - val_mae: 5.9226 - val_mse: 48.9890\n",
            "Epoch 86/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7979 - loss: 0.4746 - mae: 5.9663 - mse: 49.4244 - val_accuracy: 0.8092 - val_loss: 0.4569 - val_mae: 5.9226 - val_mse: 48.9899\n",
            "Epoch 87/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8102 - loss: 0.4599 - mae: 5.9470 - mse: 49.3078 - val_accuracy: 0.7911 - val_loss: 0.5047 - val_mae: 5.9226 - val_mse: 48.9893\n",
            "Epoch 88/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.4801 - mae: 5.9454 - mse: 49.5726 - val_accuracy: 0.7945 - val_loss: 0.4678 - val_mae: 5.9226 - val_mse: 48.9889\n",
            "Epoch 89/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7989 - loss: 0.4783 - mae: 5.9607 - mse: 49.6709 - val_accuracy: 0.8082 - val_loss: 0.4763 - val_mae: 5.9226 - val_mse: 48.9890\n",
            "Epoch 90/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8059 - loss: 0.4542 - mae: 5.9590 - mse: 49.7187 - val_accuracy: 0.7891 - val_loss: 0.4761 - val_mae: 5.9226 - val_mse: 48.9885\n",
            "Epoch 91/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7986 - loss: 0.4684 - mae: 5.9561 - mse: 49.4897 - val_accuracy: 0.7877 - val_loss: 0.4736 - val_mae: 5.9226 - val_mse: 48.9888\n",
            "Epoch 92/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8027 - loss: 0.4669 - mae: 5.9533 - mse: 49.4631 - val_accuracy: 0.8072 - val_loss: 0.4651 - val_mae: 5.9226 - val_mse: 48.9900\n",
            "Epoch 93/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7994 - loss: 0.4667 - mae: 5.9473 - mse: 49.3507 - val_accuracy: 0.8121 - val_loss: 0.4603 - val_mae: 5.9226 - val_mse: 48.9896\n",
            "Epoch 94/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8004 - loss: 0.4667 - mae: 5.9886 - mse: 49.9403 - val_accuracy: 0.8023 - val_loss: 0.4651 - val_mae: 5.9226 - val_mse: 48.9893\n",
            "Epoch 95/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4543 - mae: 5.9975 - mse: 50.1786 - val_accuracy: 0.8014 - val_loss: 0.4775 - val_mae: 5.9226 - val_mse: 48.9887\n",
            "Epoch 96/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8075 - loss: 0.4487 - mae: 5.9338 - mse: 49.3513 - val_accuracy: 0.8063 - val_loss: 0.4471 - val_mae: 5.9226 - val_mse: 48.9900\n",
            "Epoch 97/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8033 - loss: 0.4546 - mae: 5.9329 - mse: 49.3429 - val_accuracy: 0.8014 - val_loss: 0.4737 - val_mae: 5.9226 - val_mse: 48.9892\n",
            "Epoch 98/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.4598 - mae: 5.9549 - mse: 49.4499 - val_accuracy: 0.7979 - val_loss: 0.4639 - val_mae: 5.9226 - val_mse: 48.9910\n",
            "Epoch 99/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8016 - loss: 0.4633 - mae: 5.9626 - mse: 49.6605 - val_accuracy: 0.8121 - val_loss: 0.4365 - val_mae: 5.9226 - val_mse: 48.9906\n",
            "Epoch 100/100\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8093 - loss: 0.4455 - mae: 5.9208 - mse: 49.2634 - val_accuracy: 0.7916 - val_loss: 0.4878 - val_mae: 5.9226 - val_mse: 48.9889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Test"
      ],
      "metadata": {
        "id": "a82-ul9jK2OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, mae, mse = sulthan.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "\n",
        "y_pred = sulthan.predict(X_test)\n",
        "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
        "y_pred_probs = np.max(y_pred, axis=1)\n",
        "\n",
        "print(\"\\nExample Predictions:\")\n",
        "for i in range(20):\n",
        "    print(f\"Sample {i+1}: Predicted Class - {y_pred_classes[i]}, Actual Class - {y_test.iloc[i]}, Probability - {y_pred_probs[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOOENEg9BNb9",
        "outputId": "e9eeb2f2-1e07-4bb0-e52a-b86dcc77f257"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.4805\n",
            "Test Accuracy: 0.7956\n",
            "Test MAE: 5.9175\n",
            "Test MSE: 48.5663\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\n",
            "Example Predictions:\n",
            "Sample 1: Predicted Class - 7, Actual Class - 7, Probability - 0.5285\n",
            "Sample 2: Predicted Class - 3, Actual Class - 3, Probability - 0.9395\n",
            "Sample 3: Predicted Class - 4, Actual Class - 4, Probability - 1.0000\n",
            "Sample 4: Predicted Class - 10, Actual Class - 10, Probability - 0.6784\n",
            "Sample 5: Predicted Class - 2, Actual Class - 2, Probability - 0.9985\n",
            "Sample 6: Predicted Class - 0, Actual Class - 9, Probability - 0.4220\n",
            "Sample 7: Predicted Class - 12, Actual Class - 12, Probability - 0.9386\n",
            "Sample 8: Predicted Class - 8, Actual Class - 8, Probability - 0.7871\n",
            "Sample 9: Predicted Class - 11, Actual Class - 11, Probability - 0.9993\n",
            "Sample 10: Predicted Class - 1, Actual Class - 1, Probability - 0.9564\n",
            "Sample 11: Predicted Class - 11, Actual Class - 11, Probability - 0.8824\n",
            "Sample 12: Predicted Class - 4, Actual Class - 4, Probability - 1.0000\n",
            "Sample 13: Predicted Class - 0, Actual Class - 0, Probability - 0.9917\n",
            "Sample 14: Predicted Class - 0, Actual Class - 2, Probability - 0.5298\n",
            "Sample 15: Predicted Class - 3, Actual Class - 3, Probability - 0.9794\n",
            "Sample 16: Predicted Class - 5, Actual Class - 5, Probability - 0.9517\n",
            "Sample 17: Predicted Class - 10, Actual Class - 7, Probability - 0.4126\n",
            "Sample 18: Predicted Class - 9, Actual Class - 9, Probability - 0.9953\n",
            "Sample 19: Predicted Class - 1, Actual Class - 1, Probability - 0.9710\n",
            "Sample 20: Predicted Class - 12, Actual Class - 12, Probability - 0.9964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save The Model"
      ],
      "metadata": {
        "id": "QC6cv-cdM5yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model to a .keras file\n",
        "sulthan.save(\"/content/drive/MyDrive/Capstone Project/assets/model.keras\")"
      ],
      "metadata": {
        "id": "zT8y-NavM5TC"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}