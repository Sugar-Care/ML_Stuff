{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lixBK50vD8nw",
        "outputId": "99f9808f-4f3d-476a-8bf9-d52b7221e2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML_Stuff'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 58 (delta 16), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (58/58), 2.84 MiB | 5.41 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Sugar-Care/ML_Stuff.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UbxWzGlUEsrv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/ML_Stuff/Sulthan_Stuff/dataset_cleaned.csv')"
      ],
      "metadata": {
        "id": "a8XaqKwYEmNR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Age', 'Blood Glucose Levels', 'Blood Pressure', 'Weight Gain During Pregnancy',\n",
        "        'Waist Circumference', 'BMI', 'Insulin Levels', 'Cholesterol Levels',\n",
        "        'Digestive Enzyme Levels', 'Pulmonary Function']]\n",
        "y = df['Target']\n",
        "\n",
        "# Split data into training and temporary sets (80% train, 20% temp)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42) #random_state for reproducibility\n",
        "\n",
        "# Split the temporary set into validation and testing sets (50% validation, 50% test)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Now you have:\n",
        "print(len(X_train), len(y_train))\n",
        "print(len(X_val), len(y_val))\n",
        "print(len(X_test), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8jKFd-LEz1i",
        "outputId": "0f5ce4b0-a295-4965-dbe5-af98e650b4d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16354 16354\n",
            "2044 2044\n",
            "2045 2045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sulthan =  tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Conv1D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(len(df['Target'].unique()), activation='softmax')\n",
        "])\n",
        "sulthan.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mae', 'mse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19m5kPPfE-kH",
        "outputId": "3d732f02-213e-4c27-dbc7-7248bcb3baa3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sulthan.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Rv-icCyeFEB4",
        "outputId": "97b47862-f440-4d2f-a3cb-e2bc6bbb1484"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m6,208\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  │           \u001b[38;5;34m1,677\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,333\u001b[0m (63.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,333</span> (63.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,333\u001b[0m (63.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,333</span> (63.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = sulthan.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaSug9FLFGwX",
        "outputId": "368a5215-4c14-48c5-850c-b45628814639"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2162 - loss: 3.8067 - mae: 5.9215 - mse: 49.0835 - val_accuracy: 0.5245 - val_loss: 1.2800 - val_mae: 5.9226 - val_mse: 48.9576\n",
            "Epoch 2/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5235 - loss: 1.2611 - mae: 5.9623 - mse: 49.5222 - val_accuracy: 0.6267 - val_loss: 0.9374 - val_mae: 5.9226 - val_mse: 48.9674\n",
            "Epoch 3/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6093 - loss: 0.9982 - mae: 5.9273 - mse: 49.1298 - val_accuracy: 0.6659 - val_loss: 0.8378 - val_mae: 5.9226 - val_mse: 48.9717\n",
            "Epoch 4/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6375 - loss: 0.9166 - mae: 5.9253 - mse: 49.2097 - val_accuracy: 0.6551 - val_loss: 0.8454 - val_mae: 5.9226 - val_mse: 48.9741\n",
            "Epoch 5/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6530 - loss: 0.8661 - mae: 5.9142 - mse: 49.0922 - val_accuracy: 0.7045 - val_loss: 0.7454 - val_mae: 5.9226 - val_mse: 48.9755\n",
            "Epoch 6/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6633 - loss: 0.8416 - mae: 5.9428 - mse: 49.3050 - val_accuracy: 0.7021 - val_loss: 0.7423 - val_mae: 5.9226 - val_mse: 48.9758\n",
            "Epoch 7/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6740 - loss: 0.8017 - mae: 5.9820 - mse: 49.7553 - val_accuracy: 0.6908 - val_loss: 0.7401 - val_mae: 5.9226 - val_mse: 48.9781\n",
            "Epoch 8/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6861 - loss: 0.7838 - mae: 5.9335 - mse: 49.1371 - val_accuracy: 0.7387 - val_loss: 0.6787 - val_mae: 5.9226 - val_mse: 48.9781\n",
            "Epoch 9/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6926 - loss: 0.7708 - mae: 5.9708 - mse: 49.6424 - val_accuracy: 0.7089 - val_loss: 0.6984 - val_mae: 5.9226 - val_mse: 48.9781\n",
            "Epoch 10/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6988 - loss: 0.7444 - mae: 5.9358 - mse: 49.2067 - val_accuracy: 0.7280 - val_loss: 0.6702 - val_mae: 5.9226 - val_mse: 48.9808\n",
            "Epoch 11/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6992 - loss: 0.7350 - mae: 5.9647 - mse: 49.6319 - val_accuracy: 0.7265 - val_loss: 0.6863 - val_mae: 5.9226 - val_mse: 48.9793\n",
            "Epoch 12/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7065 - loss: 0.7174 - mae: 5.9433 - mse: 49.4459 - val_accuracy: 0.7412 - val_loss: 0.6519 - val_mae: 5.9226 - val_mse: 48.9804\n",
            "Epoch 13/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7118 - loss: 0.7107 - mae: 5.9332 - mse: 49.3618 - val_accuracy: 0.7192 - val_loss: 0.6981 - val_mae: 5.9226 - val_mse: 48.9804\n",
            "Epoch 14/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7071 - loss: 0.7224 - mae: 5.9305 - mse: 49.3319 - val_accuracy: 0.7466 - val_loss: 0.6387 - val_mae: 5.9226 - val_mse: 48.9804\n",
            "Epoch 15/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.6793 - mae: 5.9515 - mse: 49.3719 - val_accuracy: 0.7407 - val_loss: 0.6392 - val_mae: 5.9226 - val_mse: 48.9805\n",
            "Epoch 16/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.6739 - mae: 5.9651 - mse: 49.5900 - val_accuracy: 0.7436 - val_loss: 0.6260 - val_mae: 5.9226 - val_mse: 48.9815\n",
            "Epoch 17/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.6810 - mae: 5.9700 - mse: 49.7917 - val_accuracy: 0.7480 - val_loss: 0.6310 - val_mae: 5.9226 - val_mse: 48.9807\n",
            "Epoch 18/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7180 - loss: 0.6827 - mae: 5.9232 - mse: 49.1083 - val_accuracy: 0.7578 - val_loss: 0.6081 - val_mae: 5.9226 - val_mse: 48.9817\n",
            "Epoch 19/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.6501 - mae: 5.9717 - mse: 49.7540 - val_accuracy: 0.7529 - val_loss: 0.6133 - val_mae: 5.9226 - val_mse: 48.9831\n",
            "Epoch 20/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7328 - loss: 0.6572 - mae: 5.9395 - mse: 49.3640 - val_accuracy: 0.7441 - val_loss: 0.6162 - val_mae: 5.9226 - val_mse: 48.9832\n",
            "Epoch 21/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 0.6378 - mae: 5.9306 - mse: 49.1420 - val_accuracy: 0.7554 - val_loss: 0.6064 - val_mae: 5.9226 - val_mse: 48.9825\n",
            "Epoch 22/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6489 - mae: 5.9617 - mse: 49.6420 - val_accuracy: 0.7480 - val_loss: 0.6150 - val_mae: 5.9226 - val_mse: 48.9834\n",
            "Epoch 23/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7436 - loss: 0.6322 - mae: 5.9334 - mse: 49.2826 - val_accuracy: 0.7299 - val_loss: 0.6484 - val_mae: 5.9226 - val_mse: 48.9824\n",
            "Epoch 24/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7448 - loss: 0.6203 - mae: 5.9381 - mse: 49.5424 - val_accuracy: 0.7568 - val_loss: 0.5762 - val_mae: 5.9226 - val_mse: 48.9837\n",
            "Epoch 25/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7510 - loss: 0.6126 - mae: 5.9908 - mse: 49.8616 - val_accuracy: 0.7627 - val_loss: 0.5833 - val_mae: 5.9226 - val_mse: 48.9830\n",
            "Epoch 26/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7467 - loss: 0.6150 - mae: 5.9429 - mse: 49.3194 - val_accuracy: 0.7603 - val_loss: 0.5761 - val_mae: 5.9226 - val_mse: 48.9828\n",
            "Epoch 27/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.6066 - mae: 5.9366 - mse: 49.4391 - val_accuracy: 0.7696 - val_loss: 0.5580 - val_mae: 5.9226 - val_mse: 48.9841\n",
            "Epoch 28/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7579 - loss: 0.5926 - mae: 5.9625 - mse: 49.7290 - val_accuracy: 0.7534 - val_loss: 0.5651 - val_mae: 5.9226 - val_mse: 48.9841\n",
            "Epoch 29/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.5834 - mae: 5.9657 - mse: 49.6860 - val_accuracy: 0.7510 - val_loss: 0.5985 - val_mae: 5.9226 - val_mse: 48.9856\n",
            "Epoch 30/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7541 - loss: 0.6007 - mae: 5.9042 - mse: 48.8411 - val_accuracy: 0.7613 - val_loss: 0.5542 - val_mae: 5.9226 - val_mse: 48.9836\n",
            "Epoch 31/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7571 - loss: 0.5819 - mae: 5.9876 - mse: 50.0976 - val_accuracy: 0.7789 - val_loss: 0.5508 - val_mae: 5.9226 - val_mse: 48.9846\n",
            "Epoch 32/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7577 - loss: 0.5834 - mae: 5.9847 - mse: 49.8287 - val_accuracy: 0.7701 - val_loss: 0.5517 - val_mae: 5.9226 - val_mse: 48.9859\n",
            "Epoch 33/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7535 - loss: 0.5869 - mae: 5.9241 - mse: 49.2285 - val_accuracy: 0.7661 - val_loss: 0.5505 - val_mae: 5.9226 - val_mse: 48.9849\n",
            "Epoch 34/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7679 - loss: 0.5648 - mae: 5.9611 - mse: 49.5653 - val_accuracy: 0.7559 - val_loss: 0.5817 - val_mae: 5.9226 - val_mse: 48.9857\n",
            "Epoch 35/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7595 - loss: 0.5765 - mae: 5.9538 - mse: 49.3377 - val_accuracy: 0.7720 - val_loss: 0.5312 - val_mae: 5.9226 - val_mse: 48.9861\n",
            "Epoch 36/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7714 - loss: 0.5585 - mae: 5.9476 - mse: 49.6440 - val_accuracy: 0.7735 - val_loss: 0.5345 - val_mae: 5.9226 - val_mse: 48.9844\n",
            "Epoch 37/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.5616 - mae: 5.9832 - mse: 50.0126 - val_accuracy: 0.7764 - val_loss: 0.5271 - val_mae: 5.9226 - val_mse: 48.9853\n",
            "Epoch 38/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.5776 - mae: 5.9466 - mse: 49.5810 - val_accuracy: 0.7735 - val_loss: 0.5419 - val_mae: 5.9226 - val_mse: 48.9859\n",
            "Epoch 39/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7622 - loss: 0.5640 - mae: 5.9629 - mse: 49.6524 - val_accuracy: 0.7754 - val_loss: 0.5180 - val_mae: 5.9226 - val_mse: 48.9858\n",
            "Epoch 40/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.5668 - mae: 5.9257 - mse: 49.1771 - val_accuracy: 0.7798 - val_loss: 0.5207 - val_mae: 5.9226 - val_mse: 48.9870\n",
            "Epoch 41/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7745 - loss: 0.5416 - mae: 5.9532 - mse: 49.4837 - val_accuracy: 0.7789 - val_loss: 0.5268 - val_mae: 5.9226 - val_mse: 48.9837\n",
            "Epoch 42/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.5479 - mae: 5.9276 - mse: 49.0438 - val_accuracy: 0.7823 - val_loss: 0.5179 - val_mae: 5.9226 - val_mse: 48.9855\n",
            "Epoch 43/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.5336 - mae: 5.9531 - mse: 49.5488 - val_accuracy: 0.7828 - val_loss: 0.5217 - val_mae: 5.9226 - val_mse: 48.9877\n",
            "Epoch 44/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7686 - loss: 0.5538 - mae: 5.9164 - mse: 49.0969 - val_accuracy: 0.7891 - val_loss: 0.4987 - val_mae: 5.9226 - val_mse: 48.9865\n",
            "Epoch 45/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7744 - loss: 0.5376 - mae: 5.9086 - mse: 48.8918 - val_accuracy: 0.7891 - val_loss: 0.5032 - val_mae: 5.9226 - val_mse: 48.9862\n",
            "Epoch 46/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7724 - loss: 0.5449 - mae: 5.9129 - mse: 49.0723 - val_accuracy: 0.7872 - val_loss: 0.5009 - val_mae: 5.9226 - val_mse: 48.9859\n",
            "Epoch 47/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.5230 - mae: 5.9474 - mse: 49.5353 - val_accuracy: 0.7725 - val_loss: 0.5376 - val_mae: 5.9226 - val_mse: 48.9868\n",
            "Epoch 48/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.5361 - mae: 5.9304 - mse: 49.1904 - val_accuracy: 0.7750 - val_loss: 0.5228 - val_mae: 5.9226 - val_mse: 48.9868\n",
            "Epoch 49/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.5175 - mae: 5.9321 - mse: 49.3527 - val_accuracy: 0.7794 - val_loss: 0.5182 - val_mae: 5.9226 - val_mse: 48.9868\n",
            "Epoch 50/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.5269 - mae: 5.9735 - mse: 49.9325 - val_accuracy: 0.7940 - val_loss: 0.4878 - val_mae: 5.9226 - val_mse: 48.9880\n",
            "Epoch 51/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7746 - loss: 0.5214 - mae: 5.9013 - mse: 49.0109 - val_accuracy: 0.7950 - val_loss: 0.4811 - val_mae: 5.9226 - val_mse: 48.9873\n",
            "Epoch 52/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.5118 - mae: 5.9391 - mse: 49.3895 - val_accuracy: 0.7774 - val_loss: 0.5130 - val_mae: 5.9226 - val_mse: 48.9870\n",
            "Epoch 53/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.5209 - mae: 5.9156 - mse: 49.1673 - val_accuracy: 0.7661 - val_loss: 0.5229 - val_mae: 5.9226 - val_mse: 48.9877\n",
            "Epoch 54/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7751 - loss: 0.5243 - mae: 5.9380 - mse: 49.2868 - val_accuracy: 0.7847 - val_loss: 0.4943 - val_mae: 5.9226 - val_mse: 48.9885\n",
            "Epoch 55/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7864 - loss: 0.5096 - mae: 5.9016 - mse: 48.9382 - val_accuracy: 0.7661 - val_loss: 0.5576 - val_mae: 5.9226 - val_mse: 48.9875\n",
            "Epoch 56/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7774 - loss: 0.5165 - mae: 5.9608 - mse: 49.5903 - val_accuracy: 0.7911 - val_loss: 0.5024 - val_mae: 5.9226 - val_mse: 48.9881\n",
            "Epoch 57/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7848 - loss: 0.5026 - mae: 5.9676 - mse: 49.6729 - val_accuracy: 0.7979 - val_loss: 0.4813 - val_mae: 5.9226 - val_mse: 48.9887\n",
            "Epoch 58/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7820 - loss: 0.5107 - mae: 5.9304 - mse: 49.2771 - val_accuracy: 0.7945 - val_loss: 0.4759 - val_mae: 5.9226 - val_mse: 48.9887\n",
            "Epoch 59/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.5087 - mae: 5.9293 - mse: 49.1049 - val_accuracy: 0.7906 - val_loss: 0.4725 - val_mae: 5.9226 - val_mse: 48.9877\n",
            "Epoch 60/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.4907 - mae: 5.9816 - mse: 49.8356 - val_accuracy: 0.7896 - val_loss: 0.4881 - val_mae: 5.9226 - val_mse: 48.9877\n",
            "Epoch 61/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.4958 - mae: 5.8887 - mse: 48.9076 - val_accuracy: 0.7842 - val_loss: 0.5193 - val_mae: 5.9226 - val_mse: 48.9888\n",
            "Epoch 62/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.5166 - mae: 5.9278 - mse: 49.3255 - val_accuracy: 0.7931 - val_loss: 0.4818 - val_mae: 5.9226 - val_mse: 48.9879\n",
            "Epoch 63/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.4860 - mae: 5.9098 - mse: 49.0348 - val_accuracy: 0.7647 - val_loss: 0.5275 - val_mae: 5.9226 - val_mse: 48.9888\n",
            "Epoch 64/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7872 - loss: 0.5022 - mae: 5.9827 - mse: 49.9587 - val_accuracy: 0.7940 - val_loss: 0.4844 - val_mae: 5.9226 - val_mse: 48.9883\n",
            "Epoch 65/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.4845 - mae: 5.9735 - mse: 49.5636 - val_accuracy: 0.7935 - val_loss: 0.4962 - val_mae: 5.9226 - val_mse: 48.9884\n",
            "Epoch 66/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4822 - mae: 5.9553 - mse: 49.6152 - val_accuracy: 0.7935 - val_loss: 0.4683 - val_mae: 5.9226 - val_mse: 48.9879\n",
            "Epoch 67/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7985 - loss: 0.4790 - mae: 5.9437 - mse: 49.4312 - val_accuracy: 0.7759 - val_loss: 0.5031 - val_mae: 5.9226 - val_mse: 48.9888\n",
            "Epoch 68/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7885 - loss: 0.4843 - mae: 5.9975 - mse: 49.8956 - val_accuracy: 0.7965 - val_loss: 0.4629 - val_mae: 5.9226 - val_mse: 48.9878\n",
            "Epoch 69/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7995 - loss: 0.4689 - mae: 5.9943 - mse: 50.1523 - val_accuracy: 0.8068 - val_loss: 0.4472 - val_mae: 5.9226 - val_mse: 48.9882\n",
            "Epoch 70/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8024 - loss: 0.4635 - mae: 5.9526 - mse: 49.4824 - val_accuracy: 0.7921 - val_loss: 0.4826 - val_mae: 5.9226 - val_mse: 48.9894\n",
            "Epoch 71/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.4775 - mae: 5.9391 - mse: 49.4616 - val_accuracy: 0.7975 - val_loss: 0.4673 - val_mae: 5.9226 - val_mse: 48.9890\n",
            "Epoch 72/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.4750 - mae: 5.9265 - mse: 49.1762 - val_accuracy: 0.8092 - val_loss: 0.4605 - val_mae: 5.9226 - val_mse: 48.9880\n",
            "Epoch 73/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4685 - mae: 5.9721 - mse: 49.7944 - val_accuracy: 0.7999 - val_loss: 0.4734 - val_mae: 5.9226 - val_mse: 48.9895\n",
            "Epoch 74/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7958 - loss: 0.4803 - mae: 5.9476 - mse: 49.6649 - val_accuracy: 0.8019 - val_loss: 0.4662 - val_mae: 5.9226 - val_mse: 48.9885\n",
            "Epoch 75/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7959 - loss: 0.4771 - mae: 6.0084 - mse: 50.2489 - val_accuracy: 0.8082 - val_loss: 0.4436 - val_mae: 5.9226 - val_mse: 48.9901\n",
            "Epoch 76/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7969 - loss: 0.4719 - mae: 5.9972 - mse: 49.9774 - val_accuracy: 0.8141 - val_loss: 0.4539 - val_mae: 5.9226 - val_mse: 48.9897\n",
            "Epoch 77/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.4658 - mae: 5.9760 - mse: 49.7599 - val_accuracy: 0.8126 - val_loss: 0.4338 - val_mae: 5.9226 - val_mse: 48.9905\n",
            "Epoch 78/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8063 - loss: 0.4560 - mae: 5.9344 - mse: 49.5043 - val_accuracy: 0.8087 - val_loss: 0.4369 - val_mae: 5.9226 - val_mse: 48.9900\n",
            "Epoch 79/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4482 - mae: 5.9629 - mse: 49.6984 - val_accuracy: 0.8038 - val_loss: 0.4347 - val_mae: 5.9226 - val_mse: 48.9901\n",
            "Epoch 80/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4601 - mae: 5.9668 - mse: 49.6761 - val_accuracy: 0.8038 - val_loss: 0.4510 - val_mae: 5.9226 - val_mse: 48.9901\n",
            "Epoch 81/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.4577 - mae: 5.9766 - mse: 49.9239 - val_accuracy: 0.7886 - val_loss: 0.4935 - val_mae: 5.9226 - val_mse: 48.9911\n",
            "Epoch 82/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7929 - loss: 0.4842 - mae: 5.8984 - mse: 48.9204 - val_accuracy: 0.7999 - val_loss: 0.4691 - val_mae: 5.9226 - val_mse: 48.9903\n",
            "Epoch 83/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8050 - loss: 0.4524 - mae: 5.9303 - mse: 49.2220 - val_accuracy: 0.8116 - val_loss: 0.4321 - val_mae: 5.9226 - val_mse: 48.9906\n",
            "Epoch 84/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8090 - loss: 0.4466 - mae: 5.9499 - mse: 49.5197 - val_accuracy: 0.8009 - val_loss: 0.4481 - val_mae: 5.9226 - val_mse: 48.9905\n",
            "Epoch 85/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.4435 - mae: 5.9079 - mse: 49.0140 - val_accuracy: 0.8107 - val_loss: 0.4385 - val_mae: 5.9226 - val_mse: 48.9903\n",
            "Epoch 86/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.4410 - mae: 5.8819 - mse: 48.6775 - val_accuracy: 0.8097 - val_loss: 0.4452 - val_mae: 5.9226 - val_mse: 48.9901\n",
            "Epoch 87/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8114 - loss: 0.4449 - mae: 5.9364 - mse: 49.1997 - val_accuracy: 0.8023 - val_loss: 0.4464 - val_mae: 5.9226 - val_mse: 48.9901\n",
            "Epoch 88/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4413 - mae: 5.9547 - mse: 49.5904 - val_accuracy: 0.8224 - val_loss: 0.4152 - val_mae: 5.9226 - val_mse: 48.9907\n",
            "Epoch 89/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4508 - mae: 5.9015 - mse: 48.8724 - val_accuracy: 0.8234 - val_loss: 0.4249 - val_mae: 5.9226 - val_mse: 48.9921\n",
            "Epoch 90/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.4374 - mae: 5.9452 - mse: 49.3531 - val_accuracy: 0.8165 - val_loss: 0.4225 - val_mae: 5.9226 - val_mse: 48.9907\n",
            "Epoch 91/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4513 - mae: 5.9507 - mse: 49.5482 - val_accuracy: 0.8121 - val_loss: 0.4374 - val_mae: 5.9226 - val_mse: 48.9904\n",
            "Epoch 92/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7998 - loss: 0.4573 - mae: 5.8877 - mse: 48.7885 - val_accuracy: 0.8156 - val_loss: 0.4252 - val_mae: 5.9226 - val_mse: 48.9915\n",
            "Epoch 93/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.4266 - mae: 5.9146 - mse: 48.8873 - val_accuracy: 0.8082 - val_loss: 0.4335 - val_mae: 5.9226 - val_mse: 48.9909\n",
            "Epoch 94/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.4366 - mae: 5.8865 - mse: 48.6985 - val_accuracy: 0.8116 - val_loss: 0.4397 - val_mae: 5.9226 - val_mse: 48.9921\n",
            "Epoch 95/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.4302 - mae: 5.9368 - mse: 49.2184 - val_accuracy: 0.8033 - val_loss: 0.4499 - val_mae: 5.9226 - val_mse: 48.9904\n",
            "Epoch 96/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.4294 - mae: 5.9524 - mse: 49.4534 - val_accuracy: 0.8033 - val_loss: 0.4421 - val_mae: 5.9226 - val_mse: 48.9916\n",
            "Epoch 97/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8190 - loss: 0.4322 - mae: 5.9116 - mse: 48.9873 - val_accuracy: 0.7984 - val_loss: 0.4683 - val_mae: 5.9226 - val_mse: 48.9915\n",
            "Epoch 98/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8101 - loss: 0.4421 - mae: 5.9413 - mse: 49.4085 - val_accuracy: 0.8033 - val_loss: 0.4564 - val_mae: 5.9226 - val_mse: 48.9902\n",
            "Epoch 99/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8084 - loss: 0.4428 - mae: 5.9670 - mse: 49.5730 - val_accuracy: 0.8092 - val_loss: 0.4318 - val_mae: 5.9226 - val_mse: 48.9911\n",
            "Epoch 100/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8162 - loss: 0.4179 - mae: 5.9659 - mse: 49.5373 - val_accuracy: 0.8258 - val_loss: 0.4129 - val_mae: 5.9226 - val_mse: 48.9912\n",
            "Epoch 101/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.4205 - mae: 5.9610 - mse: 49.5088 - val_accuracy: 0.8185 - val_loss: 0.4281 - val_mae: 5.9226 - val_mse: 48.9914\n",
            "Epoch 102/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8183 - loss: 0.4204 - mae: 5.9181 - mse: 49.0181 - val_accuracy: 0.8170 - val_loss: 0.4280 - val_mae: 5.9226 - val_mse: 48.9915\n",
            "Epoch 103/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.4314 - mae: 5.9912 - mse: 49.9933 - val_accuracy: 0.8214 - val_loss: 0.4127 - val_mae: 5.9226 - val_mse: 48.9911\n",
            "Epoch 104/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.4098 - mae: 5.9637 - mse: 49.7115 - val_accuracy: 0.8244 - val_loss: 0.4109 - val_mae: 5.9226 - val_mse: 48.9908\n",
            "Epoch 105/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.4128 - mae: 5.9193 - mse: 49.0978 - val_accuracy: 0.8151 - val_loss: 0.4346 - val_mae: 5.9226 - val_mse: 48.9905\n",
            "Epoch 106/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.4296 - mae: 5.9835 - mse: 49.9322 - val_accuracy: 0.8160 - val_loss: 0.4261 - val_mae: 5.9226 - val_mse: 48.9911\n",
            "Epoch 107/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8158 - loss: 0.4223 - mae: 5.9391 - mse: 49.2984 - val_accuracy: 0.8273 - val_loss: 0.4181 - val_mae: 5.9226 - val_mse: 48.9896\n",
            "Epoch 108/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.4192 - mae: 5.9595 - mse: 49.3881 - val_accuracy: 0.8307 - val_loss: 0.3983 - val_mae: 5.9226 - val_mse: 48.9917\n",
            "Epoch 109/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 0.4015 - mae: 5.9206 - mse: 49.0183 - val_accuracy: 0.8175 - val_loss: 0.4202 - val_mae: 5.9226 - val_mse: 48.9908\n",
            "Epoch 110/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.4167 - mae: 5.9549 - mse: 49.5268 - val_accuracy: 0.8102 - val_loss: 0.4264 - val_mae: 5.9226 - val_mse: 48.9929\n",
            "Epoch 111/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8258 - loss: 0.4124 - mae: 5.9468 - mse: 49.5026 - val_accuracy: 0.8156 - val_loss: 0.4266 - val_mae: 5.9226 - val_mse: 48.9909\n",
            "Epoch 112/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8194 - loss: 0.4110 - mae: 5.9373 - mse: 49.4970 - val_accuracy: 0.8258 - val_loss: 0.4008 - val_mae: 5.9226 - val_mse: 48.9920\n",
            "Epoch 113/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8260 - loss: 0.4021 - mae: 5.9138 - mse: 49.1140 - val_accuracy: 0.8283 - val_loss: 0.3987 - val_mae: 5.9226 - val_mse: 48.9920\n",
            "Epoch 114/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.4274 - mae: 5.9893 - mse: 49.9733 - val_accuracy: 0.8156 - val_loss: 0.4241 - val_mae: 5.9226 - val_mse: 48.9916\n",
            "Epoch 115/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.4077 - mae: 5.9748 - mse: 49.7584 - val_accuracy: 0.8209 - val_loss: 0.4151 - val_mae: 5.9226 - val_mse: 48.9909\n",
            "Epoch 116/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8238 - loss: 0.4054 - mae: 5.9589 - mse: 49.5577 - val_accuracy: 0.8068 - val_loss: 0.4340 - val_mae: 5.9226 - val_mse: 48.9911\n",
            "Epoch 117/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4052 - mae: 5.9979 - mse: 50.0854 - val_accuracy: 0.8063 - val_loss: 0.4381 - val_mae: 5.9226 - val_mse: 48.9919\n",
            "Epoch 118/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.4167 - mae: 5.9834 - mse: 49.9301 - val_accuracy: 0.8356 - val_loss: 0.3937 - val_mae: 5.9226 - val_mse: 48.9925\n",
            "Epoch 119/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.4010 - mae: 5.9446 - mse: 49.4814 - val_accuracy: 0.8053 - val_loss: 0.4128 - val_mae: 5.9226 - val_mse: 48.9912\n",
            "Epoch 120/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.3998 - mae: 5.9712 - mse: 49.7400 - val_accuracy: 0.8092 - val_loss: 0.4256 - val_mae: 5.9226 - val_mse: 48.9919\n",
            "Epoch 121/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.4201 - mae: 5.9383 - mse: 49.5674 - val_accuracy: 0.8312 - val_loss: 0.4029 - val_mae: 5.9226 - val_mse: 48.9926\n",
            "Epoch 122/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.3953 - mae: 5.9536 - mse: 49.4314 - val_accuracy: 0.8195 - val_loss: 0.4030 - val_mae: 5.9226 - val_mse: 48.9927\n",
            "Epoch 123/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8343 - loss: 0.3907 - mae: 6.0024 - mse: 50.2380 - val_accuracy: 0.8307 - val_loss: 0.3918 - val_mae: 5.9226 - val_mse: 48.9927\n",
            "Epoch 124/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.3930 - mae: 5.9216 - mse: 49.1416 - val_accuracy: 0.8092 - val_loss: 0.4320 - val_mae: 5.9226 - val_mse: 48.9910\n",
            "Epoch 125/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8245 - loss: 0.4016 - mae: 5.9348 - mse: 49.2920 - val_accuracy: 0.8170 - val_loss: 0.4173 - val_mae: 5.9226 - val_mse: 48.9920\n",
            "Epoch 126/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8310 - loss: 0.3914 - mae: 5.9102 - mse: 48.9850 - val_accuracy: 0.8205 - val_loss: 0.4148 - val_mae: 5.9226 - val_mse: 48.9921\n",
            "Epoch 127/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8271 - loss: 0.3966 - mae: 5.9556 - mse: 49.6230 - val_accuracy: 0.8253 - val_loss: 0.4051 - val_mae: 5.9226 - val_mse: 48.9916\n",
            "Epoch 128/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8285 - loss: 0.4001 - mae: 5.9553 - mse: 49.5764 - val_accuracy: 0.8224 - val_loss: 0.4018 - val_mae: 5.9226 - val_mse: 48.9917\n",
            "Epoch 129/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.3927 - mae: 5.8805 - mse: 48.6653 - val_accuracy: 0.8317 - val_loss: 0.4000 - val_mae: 5.9226 - val_mse: 48.9928\n",
            "Epoch 130/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.4024 - mae: 5.9941 - mse: 49.8653 - val_accuracy: 0.8180 - val_loss: 0.4145 - val_mae: 5.9226 - val_mse: 48.9929\n",
            "Epoch 131/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8309 - loss: 0.3837 - mae: 5.9662 - mse: 49.6708 - val_accuracy: 0.8263 - val_loss: 0.3988 - val_mae: 5.9226 - val_mse: 48.9931\n",
            "Epoch 132/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 0.3853 - mae: 5.9488 - mse: 49.4871 - val_accuracy: 0.8195 - val_loss: 0.4031 - val_mae: 5.9226 - val_mse: 48.9919\n",
            "Epoch 133/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.3930 - mae: 5.9236 - mse: 49.2185 - val_accuracy: 0.8263 - val_loss: 0.3890 - val_mae: 5.9226 - val_mse: 48.9933\n",
            "Epoch 134/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 0.3858 - mae: 5.9580 - mse: 49.5823 - val_accuracy: 0.8283 - val_loss: 0.3915 - val_mae: 5.9226 - val_mse: 48.9929\n",
            "Epoch 135/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 0.3815 - mae: 5.9075 - mse: 48.9775 - val_accuracy: 0.8224 - val_loss: 0.4024 - val_mae: 5.9226 - val_mse: 48.9928\n",
            "Epoch 136/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8323 - loss: 0.3915 - mae: 5.9944 - mse: 50.1784 - val_accuracy: 0.8146 - val_loss: 0.4460 - val_mae: 5.9226 - val_mse: 48.9922\n",
            "Epoch 137/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8204 - loss: 0.4026 - mae: 5.9596 - mse: 49.5027 - val_accuracy: 0.8087 - val_loss: 0.4379 - val_mae: 5.9226 - val_mse: 48.9918\n",
            "Epoch 138/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 0.3997 - mae: 5.9161 - mse: 48.9498 - val_accuracy: 0.8341 - val_loss: 0.3919 - val_mae: 5.9226 - val_mse: 48.9935\n",
            "Epoch 139/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8341 - loss: 0.3780 - mae: 5.9141 - mse: 48.8207 - val_accuracy: 0.8302 - val_loss: 0.3893 - val_mae: 5.9226 - val_mse: 48.9925\n",
            "Epoch 140/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8280 - loss: 0.3956 - mae: 5.9996 - mse: 50.0988 - val_accuracy: 0.8146 - val_loss: 0.4206 - val_mae: 5.9226 - val_mse: 48.9933\n",
            "Epoch 141/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8325 - loss: 0.3870 - mae: 5.9782 - mse: 49.7382 - val_accuracy: 0.8366 - val_loss: 0.3880 - val_mae: 5.9226 - val_mse: 48.9921\n",
            "Epoch 142/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.3797 - mae: 5.9944 - mse: 50.0218 - val_accuracy: 0.8082 - val_loss: 0.4389 - val_mae: 5.9226 - val_mse: 48.9927\n",
            "Epoch 143/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.3948 - mae: 5.9275 - mse: 49.2632 - val_accuracy: 0.8004 - val_loss: 0.4666 - val_mae: 5.9226 - val_mse: 48.9932\n",
            "Epoch 144/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8255 - loss: 0.4115 - mae: 5.9375 - mse: 49.2685 - val_accuracy: 0.8244 - val_loss: 0.4054 - val_mae: 5.9226 - val_mse: 48.9931\n",
            "Epoch 145/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.3795 - mae: 5.9037 - mse: 48.9664 - val_accuracy: 0.8185 - val_loss: 0.4168 - val_mae: 5.9226 - val_mse: 48.9921\n",
            "Epoch 146/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8321 - loss: 0.3862 - mae: 5.9085 - mse: 49.0925 - val_accuracy: 0.8141 - val_loss: 0.4147 - val_mae: 5.9226 - val_mse: 48.9920\n",
            "Epoch 147/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8300 - loss: 0.3881 - mae: 5.9419 - mse: 49.3793 - val_accuracy: 0.8258 - val_loss: 0.3990 - val_mae: 5.9226 - val_mse: 48.9933\n",
            "Epoch 148/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.4130 - mae: 5.9609 - mse: 49.7147 - val_accuracy: 0.8297 - val_loss: 0.4264 - val_mae: 5.9226 - val_mse: 48.9938\n",
            "Epoch 149/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8343 - loss: 0.3875 - mae: 5.9680 - mse: 49.7141 - val_accuracy: 0.8283 - val_loss: 0.4006 - val_mae: 5.9226 - val_mse: 48.9933\n",
            "Epoch 150/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 0.3713 - mae: 5.9116 - mse: 48.9454 - val_accuracy: 0.8258 - val_loss: 0.3860 - val_mae: 5.9226 - val_mse: 48.9933\n",
            "Epoch 151/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.3800 - mae: 5.9432 - mse: 49.3796 - val_accuracy: 0.7926 - val_loss: 0.4681 - val_mae: 5.9226 - val_mse: 48.9912\n",
            "Epoch 152/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8241 - loss: 0.4009 - mae: 5.9677 - mse: 49.9132 - val_accuracy: 0.8273 - val_loss: 0.3970 - val_mae: 5.9226 - val_mse: 48.9936\n",
            "Epoch 153/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8418 - loss: 0.3680 - mae: 6.0176 - mse: 50.3487 - val_accuracy: 0.8009 - val_loss: 0.4571 - val_mae: 5.9226 - val_mse: 48.9913\n",
            "Epoch 154/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8300 - loss: 0.3935 - mae: 5.9591 - mse: 49.7790 - val_accuracy: 0.8322 - val_loss: 0.3847 - val_mae: 5.9226 - val_mse: 48.9936\n",
            "Epoch 155/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8367 - loss: 0.3706 - mae: 5.9745 - mse: 49.8317 - val_accuracy: 0.8253 - val_loss: 0.3978 - val_mae: 5.9226 - val_mse: 48.9922\n",
            "Epoch 156/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3731 - mae: 5.8997 - mse: 48.8308 - val_accuracy: 0.8263 - val_loss: 0.4070 - val_mae: 5.9226 - val_mse: 48.9941\n",
            "Epoch 157/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.3742 - mae: 5.9577 - mse: 49.4433 - val_accuracy: 0.8165 - val_loss: 0.4381 - val_mae: 5.9226 - val_mse: 48.9918\n",
            "Epoch 158/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.3824 - mae: 5.9037 - mse: 48.7853 - val_accuracy: 0.8371 - val_loss: 0.3795 - val_mae: 5.9226 - val_mse: 48.9943\n",
            "Epoch 159/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8423 - loss: 0.3694 - mae: 5.9321 - mse: 49.1092 - val_accuracy: 0.8121 - val_loss: 0.4221 - val_mae: 5.9226 - val_mse: 48.9934\n",
            "Epoch 160/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 0.3734 - mae: 6.0171 - mse: 50.2455 - val_accuracy: 0.8351 - val_loss: 0.3700 - val_mae: 5.9226 - val_mse: 48.9935\n",
            "Epoch 161/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.3761 - mae: 5.9536 - mse: 49.6103 - val_accuracy: 0.8307 - val_loss: 0.3819 - val_mae: 5.9226 - val_mse: 48.9928\n",
            "Epoch 162/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 0.3670 - mae: 5.9471 - mse: 49.6027 - val_accuracy: 0.8253 - val_loss: 0.3942 - val_mae: 5.9226 - val_mse: 48.9940\n",
            "Epoch 163/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.3668 - mae: 5.9186 - mse: 49.0598 - val_accuracy: 0.8293 - val_loss: 0.3856 - val_mae: 5.9226 - val_mse: 48.9931\n",
            "Epoch 164/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 0.3663 - mae: 5.9079 - mse: 49.0980 - val_accuracy: 0.7935 - val_loss: 0.4976 - val_mae: 5.9226 - val_mse: 48.9942\n",
            "Epoch 165/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8230 - loss: 0.4141 - mae: 5.9578 - mse: 49.5956 - val_accuracy: 0.8356 - val_loss: 0.3884 - val_mae: 5.9226 - val_mse: 48.9925\n",
            "Epoch 166/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8328 - loss: 0.3773 - mae: 5.9295 - mse: 49.3403 - val_accuracy: 0.8361 - val_loss: 0.3723 - val_mae: 5.9226 - val_mse: 48.9932\n",
            "Epoch 167/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8417 - loss: 0.3599 - mae: 5.9354 - mse: 49.5110 - val_accuracy: 0.8297 - val_loss: 0.3884 - val_mae: 5.9226 - val_mse: 48.9932\n",
            "Epoch 168/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8283 - loss: 0.3921 - mae: 5.9557 - mse: 49.4661 - val_accuracy: 0.8302 - val_loss: 0.3830 - val_mae: 5.9226 - val_mse: 48.9932\n",
            "Epoch 169/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 0.3748 - mae: 5.9940 - mse: 49.9667 - val_accuracy: 0.8229 - val_loss: 0.3837 - val_mae: 5.9226 - val_mse: 48.9945\n",
            "Epoch 170/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 0.3772 - mae: 5.9056 - mse: 48.9710 - val_accuracy: 0.8312 - val_loss: 0.3683 - val_mae: 5.9226 - val_mse: 48.9937\n",
            "Epoch 171/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3689 - mae: 5.9444 - mse: 49.4062 - val_accuracy: 0.8165 - val_loss: 0.3974 - val_mae: 5.9226 - val_mse: 48.9932\n",
            "Epoch 172/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8318 - loss: 0.3853 - mae: 5.9387 - mse: 49.2855 - val_accuracy: 0.8288 - val_loss: 0.3762 - val_mae: 5.9226 - val_mse: 48.9936\n",
            "Epoch 173/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 0.3591 - mae: 5.8836 - mse: 48.8152 - val_accuracy: 0.8258 - val_loss: 0.3813 - val_mae: 5.9226 - val_mse: 48.9945\n",
            "Epoch 174/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.3596 - mae: 5.9174 - mse: 49.0166 - val_accuracy: 0.8361 - val_loss: 0.3751 - val_mae: 5.9226 - val_mse: 48.9937\n",
            "Epoch 175/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.3658 - mae: 5.9483 - mse: 49.5631 - val_accuracy: 0.8312 - val_loss: 0.3929 - val_mae: 5.9226 - val_mse: 48.9941\n",
            "Epoch 176/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.3523 - mae: 5.9408 - mse: 49.3969 - val_accuracy: 0.8244 - val_loss: 0.4154 - val_mae: 5.9226 - val_mse: 48.9929\n",
            "Epoch 177/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8325 - loss: 0.3841 - mae: 5.9561 - mse: 49.6649 - val_accuracy: 0.8268 - val_loss: 0.3894 - val_mae: 5.9226 - val_mse: 48.9939\n",
            "Epoch 178/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8388 - loss: 0.3751 - mae: 5.9602 - mse: 49.7054 - val_accuracy: 0.8386 - val_loss: 0.3708 - val_mae: 5.9226 - val_mse: 48.9940\n",
            "Epoch 179/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8505 - loss: 0.3433 - mae: 5.9699 - mse: 49.7290 - val_accuracy: 0.8239 - val_loss: 0.3942 - val_mae: 5.9226 - val_mse: 48.9938\n",
            "Epoch 180/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8308 - loss: 0.3871 - mae: 5.9592 - mse: 49.5367 - val_accuracy: 0.8297 - val_loss: 0.3829 - val_mae: 5.9226 - val_mse: 48.9940\n",
            "Epoch 181/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.3642 - mae: 5.9407 - mse: 49.2472 - val_accuracy: 0.8337 - val_loss: 0.3841 - val_mae: 5.9226 - val_mse: 48.9951\n",
            "Epoch 182/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 0.3680 - mae: 5.9074 - mse: 49.0941 - val_accuracy: 0.8483 - val_loss: 0.3608 - val_mae: 5.9226 - val_mse: 48.9945\n",
            "Epoch 183/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 0.3638 - mae: 5.9028 - mse: 48.9083 - val_accuracy: 0.8312 - val_loss: 0.3965 - val_mae: 5.9226 - val_mse: 48.9948\n",
            "Epoch 184/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 0.3613 - mae: 5.9462 - mse: 49.3810 - val_accuracy: 0.8317 - val_loss: 0.3838 - val_mae: 5.9226 - val_mse: 48.9939\n",
            "Epoch 185/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8433 - loss: 0.3524 - mae: 5.9905 - mse: 49.9990 - val_accuracy: 0.8337 - val_loss: 0.3720 - val_mae: 5.9226 - val_mse: 48.9933\n",
            "Epoch 186/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8445 - loss: 0.3530 - mae: 5.9367 - mse: 49.2652 - val_accuracy: 0.8258 - val_loss: 0.3864 - val_mae: 5.9226 - val_mse: 48.9941\n",
            "Epoch 187/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3545 - mae: 5.9271 - mse: 49.2597 - val_accuracy: 0.8249 - val_loss: 0.4111 - val_mae: 5.9226 - val_mse: 48.9950\n",
            "Epoch 188/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.3506 - mae: 5.9630 - mse: 49.6910 - val_accuracy: 0.8376 - val_loss: 0.3715 - val_mae: 5.9226 - val_mse: 48.9937\n",
            "Epoch 189/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8467 - loss: 0.3460 - mae: 5.9066 - mse: 48.9780 - val_accuracy: 0.8190 - val_loss: 0.4078 - val_mae: 5.9226 - val_mse: 48.9927\n",
            "Epoch 190/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.3668 - mae: 5.9265 - mse: 49.0917 - val_accuracy: 0.8263 - val_loss: 0.3903 - val_mae: 5.9226 - val_mse: 48.9944\n",
            "Epoch 191/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8460 - loss: 0.3470 - mae: 5.9820 - mse: 49.7741 - val_accuracy: 0.8410 - val_loss: 0.3581 - val_mae: 5.9226 - val_mse: 48.9937\n",
            "Epoch 192/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8510 - loss: 0.3459 - mae: 5.9614 - mse: 49.5475 - val_accuracy: 0.8263 - val_loss: 0.3958 - val_mae: 5.9226 - val_mse: 48.9941\n",
            "Epoch 193/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 0.3614 - mae: 5.9326 - mse: 49.1946 - val_accuracy: 0.8361 - val_loss: 0.3727 - val_mae: 5.9226 - val_mse: 48.9942\n",
            "Epoch 194/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8500 - loss: 0.3466 - mae: 5.9495 - mse: 49.2994 - val_accuracy: 0.8371 - val_loss: 0.3675 - val_mae: 5.9226 - val_mse: 48.9937\n",
            "Epoch 195/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.3462 - mae: 5.9336 - mse: 49.4178 - val_accuracy: 0.8420 - val_loss: 0.3652 - val_mae: 5.9226 - val_mse: 48.9938\n",
            "Epoch 196/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8474 - loss: 0.3503 - mae: 5.9108 - mse: 48.9595 - val_accuracy: 0.8136 - val_loss: 0.4186 - val_mae: 5.9226 - val_mse: 48.9933\n",
            "Epoch 197/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.3846 - mae: 5.9520 - mse: 49.5913 - val_accuracy: 0.8258 - val_loss: 0.4045 - val_mae: 5.9226 - val_mse: 48.9932\n",
            "Epoch 198/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.3729 - mae: 5.9260 - mse: 49.2329 - val_accuracy: 0.8366 - val_loss: 0.3690 - val_mae: 5.9226 - val_mse: 48.9942\n",
            "Epoch 199/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 0.3459 - mae: 5.9645 - mse: 49.5669 - val_accuracy: 0.8444 - val_loss: 0.3756 - val_mae: 5.9226 - val_mse: 48.9946\n",
            "Epoch 200/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.3541 - mae: 5.9391 - mse: 49.4488 - val_accuracy: 0.8322 - val_loss: 0.3944 - val_mae: 5.9226 - val_mse: 48.9936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, mae, mse = sulthan.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "\n",
        "y_pred = sulthan.predict(X_test)\n",
        "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
        "y_pred_probs = np.max(y_pred, axis=1)\n",
        "\n",
        "print(\"\\nExample Predictions:\")\n",
        "for i in range(20):\n",
        "    print(f\"Sample {i+1}: Predicted Class - {y_pred_classes[i]}, Actual Class - {y_test.iloc[i]}, Probability - {y_pred_probs[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYLhmEJzFHWM",
        "outputId": "3dc6bae5-6f89-4108-b96b-61360a718dc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3960\n",
            "Test Accuracy: 0.8377\n",
            "Test MAE: 5.9175\n",
            "Test MSE: 48.5709\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Example Predictions:\n",
            "Sample 1: Predicted Class - 7, Actual Class - 7, Probability - 0.7061\n",
            "Sample 2: Predicted Class - 3, Actual Class - 3, Probability - 0.9090\n",
            "Sample 3: Predicted Class - 4, Actual Class - 4, Probability - 1.0000\n",
            "Sample 4: Predicted Class - 10, Actual Class - 10, Probability - 0.7269\n",
            "Sample 5: Predicted Class - 2, Actual Class - 2, Probability - 1.0000\n",
            "Sample 6: Predicted Class - 7, Actual Class - 9, Probability - 0.6924\n",
            "Sample 7: Predicted Class - 12, Actual Class - 12, Probability - 0.9998\n",
            "Sample 8: Predicted Class - 8, Actual Class - 8, Probability - 0.9398\n",
            "Sample 9: Predicted Class - 11, Actual Class - 11, Probability - 1.0000\n",
            "Sample 10: Predicted Class - 1, Actual Class - 1, Probability - 0.9955\n",
            "Sample 11: Predicted Class - 11, Actual Class - 11, Probability - 0.9989\n",
            "Sample 12: Predicted Class - 4, Actual Class - 4, Probability - 1.0000\n",
            "Sample 13: Predicted Class - 0, Actual Class - 0, Probability - 0.9925\n",
            "Sample 14: Predicted Class - 2, Actual Class - 2, Probability - 0.6713\n",
            "Sample 15: Predicted Class - 3, Actual Class - 3, Probability - 0.9678\n",
            "Sample 16: Predicted Class - 5, Actual Class - 5, Probability - 1.0000\n",
            "Sample 17: Predicted Class - 10, Actual Class - 7, Probability - 0.5817\n",
            "Sample 18: Predicted Class - 9, Actual Class - 9, Probability - 1.0000\n",
            "Sample 19: Predicted Class - 1, Actual Class - 1, Probability - 0.9999\n",
            "Sample 20: Predicted Class - 12, Actual Class - 12, Probability - 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sulthan.save(\"sulthan_cnn_model.keras\")"
      ],
      "metadata": {
        "id": "jAKxHeZ6FNuR"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}