{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lixBK50vD8nw",
        "outputId": "1753d052-da88-401d-c352-09afb6946f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ML_Stuff' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Sugar-Care/ML_Stuff.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "UbxWzGlUEsrv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/ML_Stuff/Dataset/dataset_diabetes_2.csv')"
      ],
      "metadata": {
        "id": "a8XaqKwYEmNR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "UDy5qiJZ1G6T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('dataset_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "hCb4I2Ew-_6m"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by='Target').reset_index(drop=True)\n",
        "df['Target_encoded'] = LabelEncoder().fit_transform(df['Target'])"
      ],
      "metadata": {
        "id": "d_saDEg71yiw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['Target', 'Target_encoded']].sample(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx9DbchB17su",
        "outputId": "34cd29a3-43a3-4d15-95e5-544d59dee4fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Target  Target_encoded\n",
            "14499                             Type 2 Diabetes               9\n",
            "12069                    Steroid-Induced Diabetes               7\n",
            "11379                    Steroid-Induced Diabetes               7\n",
            "13380                             Type 1 Diabetes               8\n",
            "16515  Type 3c Diabetes (Pancreatogenic Diabetes)              10\n",
            "3730                                         LADA               2\n",
            "19763                            Wolfram Syndrome              12\n",
            "17960                   Wolcott-Rallison Syndrome              11\n",
            "9993                           Secondary Diabetes               6\n",
            "10847                          Secondary Diabetes               6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Age', 'Blood Glucose Levels', 'Blood Pressure', 'Weight Gain During Pregnancy',\n",
        "        'Waist Circumference', 'BMI', 'Insulin Levels', 'Cholesterol Levels',\n",
        "        'Digestive Enzyme Levels', 'Pulmonary Function']]\n",
        "y = df['Target_encoded']"
      ],
      "metadata": {
        "id": "fn8pFfxS0Jgt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and temporary sets (80% train, 20% temp)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42) #random_state for reproducibility\n",
        "\n",
        "# Split the temporary set into validation and testing sets (50% validation, 50% test)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Now you have:\n",
        "print(len(X_train), len(y_train))\n",
        "print(len(X_val), len(y_val))\n",
        "print(len(X_test), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8jKFd-LEz1i",
        "outputId": "2a82ac72-b2d2-42a7-d7dc-f28f5c107cc5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16354 16354\n",
            "2044 2044\n",
            "2045 2045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sulthan =  tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Conv1D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(len(df['Target'].unique()), activation='softmax')\n",
        "])\n",
        "sulthan.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mae', 'mse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19m5kPPfE-kH",
        "outputId": "cb96cd15-bbac-49c0-f9bc-6af7cccbd070"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sulthan.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Rv-icCyeFEB4",
        "outputId": "45ec3fb4-96d9-4fb0-c234-8826fc60cfd0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m6,208\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  │           \u001b[38;5;34m1,677\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,333\u001b[0m (63.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,333</span> (63.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,333\u001b[0m (63.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,333</span> (63.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = sulthan.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaSug9FLFGwX",
        "outputId": "e84c3a93-d19e-4f88-9d04-388ef334fa8c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1978 - loss: 4.7278 - mae: 5.9431 - mse: 49.3998 - val_accuracy: 0.5470 - val_loss: 1.2581 - val_mae: 6.0269 - val_mse: 50.2553\n",
            "Epoch 2/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5201 - loss: 1.2784 - mae: 5.9135 - mse: 49.0468 - val_accuracy: 0.6414 - val_loss: 0.9431 - val_mae: 6.0269 - val_mse: 50.2663\n",
            "Epoch 3/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5972 - loss: 1.0115 - mae: 5.9199 - mse: 49.0812 - val_accuracy: 0.6595 - val_loss: 0.8522 - val_mae: 6.0269 - val_mse: 50.2714\n",
            "Epoch 4/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6382 - loss: 0.9156 - mae: 5.8873 - mse: 48.7509 - val_accuracy: 0.6546 - val_loss: 0.8787 - val_mae: 6.0269 - val_mse: 50.2738\n",
            "Epoch 5/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6593 - loss: 0.8612 - mae: 5.9565 - mse: 49.5903 - val_accuracy: 0.6810 - val_loss: 0.7777 - val_mae: 6.0269 - val_mse: 50.2743\n",
            "Epoch 6/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6681 - loss: 0.8303 - mae: 5.9979 - mse: 50.0326 - val_accuracy: 0.6810 - val_loss: 0.7925 - val_mae: 6.0269 - val_mse: 50.2769\n",
            "Epoch 7/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6764 - loss: 0.8162 - mae: 5.9266 - mse: 49.2030 - val_accuracy: 0.6972 - val_loss: 0.7188 - val_mae: 6.0269 - val_mse: 50.2769\n",
            "Epoch 8/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6880 - loss: 0.7867 - mae: 5.9404 - mse: 49.4080 - val_accuracy: 0.7065 - val_loss: 0.7291 - val_mae: 6.0269 - val_mse: 50.2788\n",
            "Epoch 9/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6918 - loss: 0.7656 - mae: 5.9367 - mse: 49.2814 - val_accuracy: 0.7114 - val_loss: 0.7063 - val_mae: 6.0269 - val_mse: 50.2789\n",
            "Epoch 10/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6974 - loss: 0.7501 - mae: 5.9600 - mse: 49.6454 - val_accuracy: 0.7133 - val_loss: 0.7009 - val_mae: 6.0269 - val_mse: 50.2777\n",
            "Epoch 11/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7060 - loss: 0.7393 - mae: 5.9254 - mse: 49.1562 - val_accuracy: 0.7187 - val_loss: 0.6780 - val_mae: 6.0269 - val_mse: 50.2795\n",
            "Epoch 12/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7099 - loss: 0.7233 - mae: 5.8902 - mse: 48.7620 - val_accuracy: 0.7133 - val_loss: 0.6906 - val_mae: 6.0269 - val_mse: 50.2805\n",
            "Epoch 13/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7042 - loss: 0.7304 - mae: 5.9351 - mse: 49.3122 - val_accuracy: 0.7172 - val_loss: 0.6788 - val_mae: 6.0269 - val_mse: 50.2791\n",
            "Epoch 14/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7067 - loss: 0.7174 - mae: 5.9109 - mse: 48.9871 - val_accuracy: 0.7241 - val_loss: 0.6692 - val_mae: 6.0269 - val_mse: 50.2806\n",
            "Epoch 15/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7165 - loss: 0.7082 - mae: 5.9028 - mse: 48.7923 - val_accuracy: 0.7123 - val_loss: 0.6711 - val_mae: 6.0269 - val_mse: 50.2804\n",
            "Epoch 16/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7138 - loss: 0.7050 - mae: 5.8729 - mse: 48.6087 - val_accuracy: 0.7231 - val_loss: 0.6639 - val_mae: 6.0269 - val_mse: 50.2807\n",
            "Epoch 17/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7101 - loss: 0.7092 - mae: 5.9668 - mse: 49.6621 - val_accuracy: 0.7250 - val_loss: 0.6539 - val_mae: 6.0269 - val_mse: 50.2831\n",
            "Epoch 18/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7185 - loss: 0.6920 - mae: 5.9384 - mse: 49.3761 - val_accuracy: 0.7123 - val_loss: 0.6762 - val_mae: 6.0269 - val_mse: 50.2814\n",
            "Epoch 19/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7229 - loss: 0.6773 - mae: 5.9963 - mse: 49.9360 - val_accuracy: 0.7280 - val_loss: 0.6574 - val_mae: 6.0269 - val_mse: 50.2818\n",
            "Epoch 20/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7230 - loss: 0.6901 - mae: 5.9272 - mse: 49.1676 - val_accuracy: 0.7187 - val_loss: 0.6497 - val_mae: 6.0269 - val_mse: 50.2818\n",
            "Epoch 21/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7252 - loss: 0.6589 - mae: 5.8600 - mse: 48.3799 - val_accuracy: 0.7226 - val_loss: 0.6597 - val_mae: 6.0269 - val_mse: 50.2835\n",
            "Epoch 22/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7196 - loss: 0.6816 - mae: 5.9421 - mse: 49.4181 - val_accuracy: 0.7432 - val_loss: 0.6245 - val_mae: 6.0269 - val_mse: 50.2820\n",
            "Epoch 23/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 0.6571 - mae: 5.9669 - mse: 49.6075 - val_accuracy: 0.7334 - val_loss: 0.6485 - val_mae: 6.0269 - val_mse: 50.2825\n",
            "Epoch 24/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7282 - loss: 0.6656 - mae: 5.9563 - mse: 49.4533 - val_accuracy: 0.7343 - val_loss: 0.6275 - val_mae: 6.0269 - val_mse: 50.2833\n",
            "Epoch 25/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7453 - loss: 0.6358 - mae: 5.9185 - mse: 49.0310 - val_accuracy: 0.7432 - val_loss: 0.6307 - val_mae: 6.0269 - val_mse: 50.2817\n",
            "Epoch 26/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7282 - loss: 0.6543 - mae: 5.8708 - mse: 48.5220 - val_accuracy: 0.7476 - val_loss: 0.6128 - val_mae: 6.0269 - val_mse: 50.2821\n",
            "Epoch 27/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.6430 - mae: 5.9163 - mse: 49.0098 - val_accuracy: 0.7324 - val_loss: 0.6074 - val_mae: 6.0269 - val_mse: 50.2824\n",
            "Epoch 28/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.6308 - mae: 5.8895 - mse: 48.6311 - val_accuracy: 0.7348 - val_loss: 0.6168 - val_mae: 6.0269 - val_mse: 50.2821\n",
            "Epoch 29/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7377 - loss: 0.6324 - mae: 5.9570 - mse: 49.5676 - val_accuracy: 0.7456 - val_loss: 0.6018 - val_mae: 6.0269 - val_mse: 50.2833\n",
            "Epoch 30/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7474 - loss: 0.6113 - mae: 5.9225 - mse: 49.3877 - val_accuracy: 0.7495 - val_loss: 0.5878 - val_mae: 6.0269 - val_mse: 50.2835\n",
            "Epoch 31/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.5961 - mae: 5.9436 - mse: 49.2695 - val_accuracy: 0.7495 - val_loss: 0.6077 - val_mae: 6.0269 - val_mse: 50.2829\n",
            "Epoch 32/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7527 - loss: 0.6128 - mae: 5.9263 - mse: 49.2172 - val_accuracy: 0.7466 - val_loss: 0.6041 - val_mae: 6.0269 - val_mse: 50.2843\n",
            "Epoch 33/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7403 - loss: 0.6215 - mae: 5.9214 - mse: 49.2413 - val_accuracy: 0.7407 - val_loss: 0.5844 - val_mae: 6.0269 - val_mse: 50.2836\n",
            "Epoch 34/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.6078 - mae: 5.9635 - mse: 49.7347 - val_accuracy: 0.7461 - val_loss: 0.5961 - val_mae: 6.0269 - val_mse: 50.2845\n",
            "Epoch 35/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 0.5947 - mae: 5.9367 - mse: 49.1738 - val_accuracy: 0.7564 - val_loss: 0.5772 - val_mae: 6.0269 - val_mse: 50.2842\n",
            "Epoch 36/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7459 - loss: 0.6112 - mae: 5.9371 - mse: 49.2439 - val_accuracy: 0.7578 - val_loss: 0.5795 - val_mae: 6.0269 - val_mse: 50.2831\n",
            "Epoch 37/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.5848 - mae: 5.9326 - mse: 49.2099 - val_accuracy: 0.7476 - val_loss: 0.5954 - val_mae: 6.0269 - val_mse: 50.2846\n",
            "Epoch 38/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.5837 - mae: 5.9441 - mse: 49.4347 - val_accuracy: 0.7500 - val_loss: 0.5909 - val_mae: 6.0269 - val_mse: 50.2831\n",
            "Epoch 39/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7548 - loss: 0.5818 - mae: 5.9648 - mse: 49.7264 - val_accuracy: 0.7568 - val_loss: 0.5555 - val_mae: 6.0269 - val_mse: 50.2851\n",
            "Epoch 40/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7487 - loss: 0.5983 - mae: 5.8821 - mse: 48.5948 - val_accuracy: 0.7608 - val_loss: 0.5708 - val_mae: 6.0269 - val_mse: 50.2842\n",
            "Epoch 41/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7591 - loss: 0.5834 - mae: 5.9396 - mse: 49.2614 - val_accuracy: 0.7627 - val_loss: 0.5772 - val_mae: 6.0269 - val_mse: 50.2845\n",
            "Epoch 42/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.5825 - mae: 5.8984 - mse: 48.8852 - val_accuracy: 0.7378 - val_loss: 0.5847 - val_mae: 6.0269 - val_mse: 50.2842\n",
            "Epoch 43/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7626 - loss: 0.5703 - mae: 5.9547 - mse: 49.5570 - val_accuracy: 0.7647 - val_loss: 0.5478 - val_mae: 6.0269 - val_mse: 50.2843\n",
            "Epoch 44/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.5773 - mae: 5.8616 - mse: 48.5066 - val_accuracy: 0.7637 - val_loss: 0.5461 - val_mae: 6.0269 - val_mse: 50.2857\n",
            "Epoch 45/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7676 - loss: 0.5491 - mae: 5.9436 - mse: 49.4555 - val_accuracy: 0.7657 - val_loss: 0.5522 - val_mae: 6.0269 - val_mse: 50.2863\n",
            "Epoch 46/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7680 - loss: 0.5612 - mae: 5.9663 - mse: 49.7279 - val_accuracy: 0.7671 - val_loss: 0.5662 - val_mae: 6.0269 - val_mse: 50.2841\n",
            "Epoch 47/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7723 - loss: 0.5479 - mae: 5.9492 - mse: 49.3593 - val_accuracy: 0.7671 - val_loss: 0.5518 - val_mae: 6.0269 - val_mse: 50.2868\n",
            "Epoch 48/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7670 - loss: 0.5528 - mae: 5.9498 - mse: 49.4833 - val_accuracy: 0.7627 - val_loss: 0.5680 - val_mae: 6.0269 - val_mse: 50.2858\n",
            "Epoch 49/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7653 - loss: 0.5697 - mae: 5.9079 - mse: 49.0651 - val_accuracy: 0.7529 - val_loss: 0.5686 - val_mae: 6.0269 - val_mse: 50.2859\n",
            "Epoch 50/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.5563 - mae: 5.9881 - mse: 49.8819 - val_accuracy: 0.7661 - val_loss: 0.5340 - val_mae: 6.0269 - val_mse: 50.2869\n",
            "Epoch 51/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.5453 - mae: 5.9566 - mse: 49.4563 - val_accuracy: 0.7696 - val_loss: 0.5362 - val_mae: 6.0269 - val_mse: 50.2867\n",
            "Epoch 52/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.5434 - mae: 5.9604 - mse: 49.7539 - val_accuracy: 0.7622 - val_loss: 0.5368 - val_mae: 6.0269 - val_mse: 50.2870\n",
            "Epoch 53/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7693 - loss: 0.5444 - mae: 5.9363 - mse: 49.2811 - val_accuracy: 0.7676 - val_loss: 0.5360 - val_mae: 6.0269 - val_mse: 50.2874\n",
            "Epoch 54/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.5411 - mae: 5.9278 - mse: 49.2138 - val_accuracy: 0.7759 - val_loss: 0.5168 - val_mae: 6.0269 - val_mse: 50.2864\n",
            "Epoch 55/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7736 - loss: 0.5513 - mae: 5.9439 - mse: 49.2837 - val_accuracy: 0.7730 - val_loss: 0.5257 - val_mae: 6.0269 - val_mse: 50.2865\n",
            "Epoch 56/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.5254 - mae: 5.9345 - mse: 49.4445 - val_accuracy: 0.7617 - val_loss: 0.5347 - val_mae: 6.0269 - val_mse: 50.2862\n",
            "Epoch 57/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.5212 - mae: 5.9006 - mse: 49.0039 - val_accuracy: 0.7730 - val_loss: 0.5288 - val_mae: 6.0269 - val_mse: 50.2859\n",
            "Epoch 58/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7712 - loss: 0.5429 - mae: 5.8755 - mse: 48.5558 - val_accuracy: 0.7803 - val_loss: 0.5113 - val_mae: 6.0269 - val_mse: 50.2874\n",
            "Epoch 59/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7878 - loss: 0.5131 - mae: 5.9902 - mse: 49.7605 - val_accuracy: 0.7808 - val_loss: 0.5188 - val_mae: 6.0269 - val_mse: 50.2867\n",
            "Epoch 60/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7811 - loss: 0.5224 - mae: 5.9790 - mse: 49.8619 - val_accuracy: 0.7794 - val_loss: 0.5076 - val_mae: 6.0269 - val_mse: 50.2864\n",
            "Epoch 61/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7758 - loss: 0.5394 - mae: 5.9473 - mse: 49.2534 - val_accuracy: 0.7754 - val_loss: 0.5064 - val_mae: 6.0269 - val_mse: 50.2871\n",
            "Epoch 62/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7879 - loss: 0.5128 - mae: 5.9351 - mse: 49.3791 - val_accuracy: 0.7774 - val_loss: 0.5083 - val_mae: 6.0269 - val_mse: 50.2882\n",
            "Epoch 63/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7870 - loss: 0.5128 - mae: 5.9227 - mse: 49.2477 - val_accuracy: 0.7833 - val_loss: 0.5147 - val_mae: 6.0269 - val_mse: 50.2871\n",
            "Epoch 64/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7781 - loss: 0.5278 - mae: 5.8815 - mse: 48.7108 - val_accuracy: 0.7740 - val_loss: 0.4990 - val_mae: 6.0269 - val_mse: 50.2880\n",
            "Epoch 65/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.5129 - mae: 5.9010 - mse: 48.8710 - val_accuracy: 0.7842 - val_loss: 0.4992 - val_mae: 6.0269 - val_mse: 50.2881\n",
            "Epoch 66/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7835 - loss: 0.5114 - mae: 5.9136 - mse: 49.0349 - val_accuracy: 0.7735 - val_loss: 0.5028 - val_mae: 6.0269 - val_mse: 50.2880\n",
            "Epoch 67/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.4996 - mae: 5.9720 - mse: 49.7029 - val_accuracy: 0.7798 - val_loss: 0.4967 - val_mae: 6.0269 - val_mse: 50.2891\n",
            "Epoch 68/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.5026 - mae: 5.9404 - mse: 49.3551 - val_accuracy: 0.7720 - val_loss: 0.5042 - val_mae: 6.0269 - val_mse: 50.2876\n",
            "Epoch 69/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.5037 - mae: 5.8980 - mse: 48.6788 - val_accuracy: 0.7789 - val_loss: 0.4995 - val_mae: 6.0269 - val_mse: 50.2878\n",
            "Epoch 70/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7942 - loss: 0.4971 - mae: 5.9869 - mse: 49.9450 - val_accuracy: 0.7975 - val_loss: 0.4690 - val_mae: 6.0269 - val_mse: 50.2874\n",
            "Epoch 71/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7955 - loss: 0.4797 - mae: 5.9353 - mse: 49.2584 - val_accuracy: 0.7886 - val_loss: 0.4915 - val_mae: 6.0269 - val_mse: 50.2875\n",
            "Epoch 72/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7889 - loss: 0.4938 - mae: 5.9527 - mse: 49.4547 - val_accuracy: 0.7916 - val_loss: 0.4769 - val_mae: 6.0269 - val_mse: 50.2891\n",
            "Epoch 73/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7954 - loss: 0.4917 - mae: 5.9702 - mse: 49.6390 - val_accuracy: 0.7877 - val_loss: 0.4799 - val_mae: 6.0269 - val_mse: 50.2890\n",
            "Epoch 74/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7906 - loss: 0.4989 - mae: 5.9130 - mse: 49.2154 - val_accuracy: 0.7857 - val_loss: 0.4877 - val_mae: 6.0269 - val_mse: 50.2887\n",
            "Epoch 75/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7950 - loss: 0.4880 - mae: 5.9313 - mse: 49.1994 - val_accuracy: 0.7975 - val_loss: 0.4613 - val_mae: 6.0269 - val_mse: 50.2893\n",
            "Epoch 76/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 0.4837 - mae: 5.9327 - mse: 49.4094 - val_accuracy: 0.7798 - val_loss: 0.5090 - val_mae: 6.0269 - val_mse: 50.2885\n",
            "Epoch 77/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.4823 - mae: 5.9269 - mse: 49.0574 - val_accuracy: 0.7960 - val_loss: 0.4646 - val_mae: 6.0269 - val_mse: 50.2899\n",
            "Epoch 78/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.4876 - mae: 5.9463 - mse: 49.3693 - val_accuracy: 0.7872 - val_loss: 0.4857 - val_mae: 6.0269 - val_mse: 50.2877\n",
            "Epoch 79/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7928 - loss: 0.4758 - mae: 5.9319 - mse: 49.2792 - val_accuracy: 0.7921 - val_loss: 0.4734 - val_mae: 6.0269 - val_mse: 50.2893\n",
            "Epoch 80/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.4718 - mae: 5.9379 - mse: 49.3153 - val_accuracy: 0.7931 - val_loss: 0.4623 - val_mae: 6.0269 - val_mse: 50.2888\n",
            "Epoch 81/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4705 - mae: 5.9376 - mse: 49.4216 - val_accuracy: 0.7940 - val_loss: 0.4615 - val_mae: 6.0269 - val_mse: 50.2896\n",
            "Epoch 82/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8043 - loss: 0.4579 - mae: 5.9432 - mse: 49.2650 - val_accuracy: 0.7838 - val_loss: 0.4794 - val_mae: 6.0269 - val_mse: 50.2887\n",
            "Epoch 83/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8076 - loss: 0.4556 - mae: 5.9007 - mse: 48.9351 - val_accuracy: 0.8043 - val_loss: 0.4555 - val_mae: 6.0269 - val_mse: 50.2887\n",
            "Epoch 84/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8004 - loss: 0.4693 - mae: 5.9729 - mse: 49.8253 - val_accuracy: 0.8048 - val_loss: 0.4440 - val_mae: 6.0269 - val_mse: 50.2899\n",
            "Epoch 85/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8028 - loss: 0.4655 - mae: 5.9543 - mse: 49.5050 - val_accuracy: 0.8092 - val_loss: 0.4525 - val_mae: 6.0269 - val_mse: 50.2875\n",
            "Epoch 86/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4568 - mae: 5.9305 - mse: 49.2885 - val_accuracy: 0.7931 - val_loss: 0.4922 - val_mae: 6.0269 - val_mse: 50.2886\n",
            "Epoch 87/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8018 - loss: 0.4631 - mae: 5.9116 - mse: 48.9917 - val_accuracy: 0.8038 - val_loss: 0.4492 - val_mae: 6.0269 - val_mse: 50.2897\n",
            "Epoch 88/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4524 - mae: 5.9014 - mse: 48.8553 - val_accuracy: 0.8019 - val_loss: 0.4465 - val_mae: 6.0269 - val_mse: 50.2899\n",
            "Epoch 89/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8183 - loss: 0.4408 - mae: 5.9071 - mse: 48.8497 - val_accuracy: 0.8097 - val_loss: 0.4339 - val_mae: 6.0269 - val_mse: 50.2895\n",
            "Epoch 90/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.4381 - mae: 5.9100 - mse: 48.9111 - val_accuracy: 0.8028 - val_loss: 0.4487 - val_mae: 6.0269 - val_mse: 50.2890\n",
            "Epoch 91/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.4466 - mae: 5.9350 - mse: 49.3233 - val_accuracy: 0.7955 - val_loss: 0.4745 - val_mae: 6.0269 - val_mse: 50.2892\n",
            "Epoch 92/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.4533 - mae: 5.9168 - mse: 49.2034 - val_accuracy: 0.7989 - val_loss: 0.4385 - val_mae: 6.0269 - val_mse: 50.2906\n",
            "Epoch 93/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 0.4605 - mae: 5.9117 - mse: 49.0523 - val_accuracy: 0.8063 - val_loss: 0.4462 - val_mae: 6.0269 - val_mse: 50.2893\n",
            "Epoch 94/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4466 - mae: 5.9065 - mse: 48.9937 - val_accuracy: 0.7764 - val_loss: 0.5078 - val_mae: 6.0269 - val_mse: 50.2892\n",
            "Epoch 95/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8016 - loss: 0.4611 - mae: 5.9560 - mse: 49.5320 - val_accuracy: 0.8014 - val_loss: 0.4436 - val_mae: 6.0269 - val_mse: 50.2908\n",
            "Epoch 96/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8162 - loss: 0.4333 - mae: 5.9429 - mse: 49.3187 - val_accuracy: 0.8048 - val_loss: 0.4318 - val_mae: 6.0269 - val_mse: 50.2901\n",
            "Epoch 97/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8121 - loss: 0.4308 - mae: 5.9583 - mse: 49.5445 - val_accuracy: 0.8116 - val_loss: 0.4190 - val_mae: 6.0269 - val_mse: 50.2902\n",
            "Epoch 98/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8206 - loss: 0.4291 - mae: 5.8870 - mse: 48.5966 - val_accuracy: 0.8063 - val_loss: 0.4372 - val_mae: 6.0269 - val_mse: 50.2912\n",
            "Epoch 99/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8146 - loss: 0.4371 - mae: 5.9739 - mse: 49.7147 - val_accuracy: 0.8023 - val_loss: 0.4451 - val_mae: 6.0269 - val_mse: 50.2901\n",
            "Epoch 100/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.4318 - mae: 5.9168 - mse: 49.0672 - val_accuracy: 0.8141 - val_loss: 0.4149 - val_mae: 6.0269 - val_mse: 50.2911\n",
            "Epoch 101/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8206 - loss: 0.4294 - mae: 5.9190 - mse: 49.1532 - val_accuracy: 0.8116 - val_loss: 0.4132 - val_mae: 6.0269 - val_mse: 50.2915\n",
            "Epoch 102/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.4283 - mae: 5.9130 - mse: 49.0630 - val_accuracy: 0.7984 - val_loss: 0.4450 - val_mae: 6.0269 - val_mse: 50.2907\n",
            "Epoch 103/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8140 - loss: 0.4422 - mae: 5.9422 - mse: 49.3094 - val_accuracy: 0.8092 - val_loss: 0.4088 - val_mae: 6.0269 - val_mse: 50.2913\n",
            "Epoch 104/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8182 - loss: 0.4235 - mae: 5.9119 - mse: 49.0534 - val_accuracy: 0.8195 - val_loss: 0.4121 - val_mae: 6.0269 - val_mse: 50.2909\n",
            "Epoch 105/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8174 - loss: 0.4226 - mae: 5.9211 - mse: 49.1834 - val_accuracy: 0.8121 - val_loss: 0.4241 - val_mae: 6.0269 - val_mse: 50.2910\n",
            "Epoch 106/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.4235 - mae: 5.9348 - mse: 49.2231 - val_accuracy: 0.8033 - val_loss: 0.4306 - val_mae: 6.0269 - val_mse: 50.2904\n",
            "Epoch 107/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.4056 - mae: 5.8984 - mse: 48.8688 - val_accuracy: 0.8087 - val_loss: 0.4349 - val_mae: 6.0269 - val_mse: 50.2905\n",
            "Epoch 108/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.4136 - mae: 5.9643 - mse: 49.5331 - val_accuracy: 0.8156 - val_loss: 0.4337 - val_mae: 6.0269 - val_mse: 50.2912\n",
            "Epoch 109/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8166 - loss: 0.4302 - mae: 5.9129 - mse: 48.9951 - val_accuracy: 0.8160 - val_loss: 0.4234 - val_mae: 6.0269 - val_mse: 50.2904\n",
            "Epoch 110/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8252 - loss: 0.4054 - mae: 5.9448 - mse: 49.3013 - val_accuracy: 0.8170 - val_loss: 0.4002 - val_mae: 6.0269 - val_mse: 50.2916\n",
            "Epoch 111/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8269 - loss: 0.4025 - mae: 5.9383 - mse: 49.3794 - val_accuracy: 0.8068 - val_loss: 0.4360 - val_mae: 6.0269 - val_mse: 50.2918\n",
            "Epoch 112/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8203 - loss: 0.4142 - mae: 5.9034 - mse: 48.8222 - val_accuracy: 0.8214 - val_loss: 0.4023 - val_mae: 6.0269 - val_mse: 50.2906\n",
            "Epoch 113/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 0.4227 - mae: 5.9577 - mse: 49.6584 - val_accuracy: 0.8087 - val_loss: 0.4379 - val_mae: 6.0269 - val_mse: 50.2910\n",
            "Epoch 114/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 0.4041 - mae: 5.9070 - mse: 49.0547 - val_accuracy: 0.8077 - val_loss: 0.4159 - val_mae: 6.0269 - val_mse: 50.2912\n",
            "Epoch 115/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.4250 - mae: 5.9299 - mse: 49.2856 - val_accuracy: 0.8121 - val_loss: 0.4001 - val_mae: 6.0269 - val_mse: 50.2917\n",
            "Epoch 116/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.4053 - mae: 5.9138 - mse: 48.9671 - val_accuracy: 0.8097 - val_loss: 0.4101 - val_mae: 6.0269 - val_mse: 50.2910\n",
            "Epoch 117/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8259 - loss: 0.4068 - mae: 5.9564 - mse: 49.6591 - val_accuracy: 0.8170 - val_loss: 0.4049 - val_mae: 6.0269 - val_mse: 50.2921\n",
            "Epoch 118/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.4108 - mae: 5.9234 - mse: 49.0827 - val_accuracy: 0.8023 - val_loss: 0.4724 - val_mae: 6.0269 - val_mse: 50.2917\n",
            "Epoch 119/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 0.4212 - mae: 5.9743 - mse: 49.8168 - val_accuracy: 0.8092 - val_loss: 0.4265 - val_mae: 6.0269 - val_mse: 50.2911\n",
            "Epoch 120/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.4132 - mae: 5.9509 - mse: 49.3158 - val_accuracy: 0.8160 - val_loss: 0.4059 - val_mae: 6.0269 - val_mse: 50.2911\n",
            "Epoch 121/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8228 - loss: 0.4063 - mae: 5.9629 - mse: 49.7379 - val_accuracy: 0.8190 - val_loss: 0.4079 - val_mae: 6.0269 - val_mse: 50.2912\n",
            "Epoch 122/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8304 - loss: 0.3953 - mae: 5.9356 - mse: 49.2439 - val_accuracy: 0.8224 - val_loss: 0.4025 - val_mae: 6.0269 - val_mse: 50.2920\n",
            "Epoch 123/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8202 - loss: 0.4194 - mae: 5.9732 - mse: 49.8610 - val_accuracy: 0.8072 - val_loss: 0.4175 - val_mae: 6.0269 - val_mse: 50.2915\n",
            "Epoch 124/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8269 - loss: 0.4053 - mae: 5.9342 - mse: 49.3529 - val_accuracy: 0.8214 - val_loss: 0.3917 - val_mae: 6.0269 - val_mse: 50.2918\n",
            "Epoch 125/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8211 - loss: 0.4187 - mae: 5.9160 - mse: 49.0707 - val_accuracy: 0.8170 - val_loss: 0.3953 - val_mae: 6.0269 - val_mse: 50.2919\n",
            "Epoch 126/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.4105 - mae: 5.9007 - mse: 48.8380 - val_accuracy: 0.8195 - val_loss: 0.4030 - val_mae: 6.0269 - val_mse: 50.2919\n",
            "Epoch 127/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.4034 - mae: 5.9569 - mse: 49.5439 - val_accuracy: 0.8072 - val_loss: 0.4133 - val_mae: 6.0269 - val_mse: 50.2914\n",
            "Epoch 128/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.3995 - mae: 5.8902 - mse: 48.7067 - val_accuracy: 0.8214 - val_loss: 0.3970 - val_mae: 6.0269 - val_mse: 50.2925\n",
            "Epoch 129/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.3894 - mae: 5.9445 - mse: 49.4487 - val_accuracy: 0.8126 - val_loss: 0.4192 - val_mae: 6.0269 - val_mse: 50.2914\n",
            "Epoch 130/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.4073 - mae: 5.9090 - mse: 49.0391 - val_accuracy: 0.8229 - val_loss: 0.3909 - val_mae: 6.0269 - val_mse: 50.2921\n",
            "Epoch 131/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8359 - loss: 0.3784 - mae: 5.9603 - mse: 49.7598 - val_accuracy: 0.8092 - val_loss: 0.4260 - val_mae: 6.0269 - val_mse: 50.2927\n",
            "Epoch 132/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.4051 - mae: 5.9555 - mse: 49.4040 - val_accuracy: 0.8092 - val_loss: 0.4102 - val_mae: 6.0269 - val_mse: 50.2929\n",
            "Epoch 133/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8356 - loss: 0.3792 - mae: 5.9261 - mse: 49.1660 - val_accuracy: 0.8234 - val_loss: 0.4086 - val_mae: 6.0269 - val_mse: 50.2920\n",
            "Epoch 134/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8300 - loss: 0.3938 - mae: 5.8914 - mse: 48.8013 - val_accuracy: 0.8200 - val_loss: 0.4143 - val_mae: 6.0269 - val_mse: 50.2912\n",
            "Epoch 135/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8391 - loss: 0.3857 - mae: 5.9347 - mse: 49.2243 - val_accuracy: 0.8229 - val_loss: 0.3906 - val_mae: 6.0269 - val_mse: 50.2929\n",
            "Epoch 136/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8327 - loss: 0.3856 - mae: 5.9409 - mse: 49.4458 - val_accuracy: 0.8249 - val_loss: 0.4008 - val_mae: 6.0269 - val_mse: 50.2924\n",
            "Epoch 137/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8375 - loss: 0.3871 - mae: 5.9229 - mse: 49.0843 - val_accuracy: 0.8121 - val_loss: 0.4247 - val_mae: 6.0269 - val_mse: 50.2922\n",
            "Epoch 138/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.3986 - mae: 5.9110 - mse: 49.0001 - val_accuracy: 0.8283 - val_loss: 0.4026 - val_mae: 6.0269 - val_mse: 50.2918\n",
            "Epoch 139/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.3872 - mae: 5.9264 - mse: 49.1763 - val_accuracy: 0.8180 - val_loss: 0.3989 - val_mae: 6.0269 - val_mse: 50.2923\n",
            "Epoch 140/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 0.3776 - mae: 5.9439 - mse: 49.5234 - val_accuracy: 0.8224 - val_loss: 0.3992 - val_mae: 6.0269 - val_mse: 50.2934\n",
            "Epoch 141/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 0.3734 - mae: 5.9331 - mse: 49.4055 - val_accuracy: 0.8258 - val_loss: 0.3887 - val_mae: 6.0269 - val_mse: 50.2916\n",
            "Epoch 142/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 0.3772 - mae: 5.9223 - mse: 49.1573 - val_accuracy: 0.8156 - val_loss: 0.4004 - val_mae: 6.0269 - val_mse: 50.2933\n",
            "Epoch 143/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.3856 - mae: 5.9258 - mse: 49.1565 - val_accuracy: 0.8249 - val_loss: 0.3904 - val_mae: 6.0269 - val_mse: 50.2922\n",
            "Epoch 144/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.3818 - mae: 5.9459 - mse: 49.5633 - val_accuracy: 0.8190 - val_loss: 0.3940 - val_mae: 6.0269 - val_mse: 50.2930\n",
            "Epoch 145/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.3775 - mae: 5.9708 - mse: 49.6328 - val_accuracy: 0.8126 - val_loss: 0.4178 - val_mae: 6.0269 - val_mse: 50.2922\n",
            "Epoch 146/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.3804 - mae: 5.9095 - mse: 49.0471 - val_accuracy: 0.8004 - val_loss: 0.4383 - val_mae: 6.0269 - val_mse: 50.2926\n",
            "Epoch 147/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8439 - loss: 0.3675 - mae: 5.9675 - mse: 49.7290 - val_accuracy: 0.8253 - val_loss: 0.3844 - val_mae: 6.0269 - val_mse: 50.2927\n",
            "Epoch 148/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 0.3648 - mae: 5.9249 - mse: 49.1409 - val_accuracy: 0.8239 - val_loss: 0.3872 - val_mae: 6.0269 - val_mse: 50.2931\n",
            "Epoch 149/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8385 - loss: 0.3742 - mae: 5.9916 - mse: 50.2263 - val_accuracy: 0.8209 - val_loss: 0.3967 - val_mae: 6.0269 - val_mse: 50.2933\n",
            "Epoch 150/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8340 - loss: 0.3822 - mae: 5.9135 - mse: 49.0540 - val_accuracy: 0.8170 - val_loss: 0.4144 - val_mae: 6.0269 - val_mse: 50.2926\n",
            "Epoch 151/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8255 - loss: 0.4045 - mae: 5.9295 - mse: 49.1793 - val_accuracy: 0.8239 - val_loss: 0.3788 - val_mae: 6.0269 - val_mse: 50.2935\n",
            "Epoch 152/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8309 - loss: 0.3843 - mae: 5.8941 - mse: 48.9239 - val_accuracy: 0.7950 - val_loss: 0.4855 - val_mae: 6.0269 - val_mse: 50.2920\n",
            "Epoch 153/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.4054 - mae: 5.9355 - mse: 49.3814 - val_accuracy: 0.8180 - val_loss: 0.3979 - val_mae: 6.0269 - val_mse: 50.2924\n",
            "Epoch 154/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8347 - loss: 0.3753 - mae: 5.9179 - mse: 49.2251 - val_accuracy: 0.8293 - val_loss: 0.3768 - val_mae: 6.0269 - val_mse: 50.2937\n",
            "Epoch 155/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.3694 - mae: 5.8798 - mse: 48.6388 - val_accuracy: 0.8209 - val_loss: 0.3863 - val_mae: 6.0269 - val_mse: 50.2930\n",
            "Epoch 156/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8292 - loss: 0.3904 - mae: 5.8753 - mse: 48.6391 - val_accuracy: 0.8278 - val_loss: 0.3906 - val_mae: 6.0269 - val_mse: 50.2930\n",
            "Epoch 157/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8344 - loss: 0.3905 - mae: 5.9156 - mse: 49.2226 - val_accuracy: 0.8302 - val_loss: 0.3792 - val_mae: 6.0269 - val_mse: 50.2932\n",
            "Epoch 158/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 0.3795 - mae: 5.9191 - mse: 49.0632 - val_accuracy: 0.8195 - val_loss: 0.3936 - val_mae: 6.0269 - val_mse: 50.2937\n",
            "Epoch 159/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.3762 - mae: 5.9159 - mse: 49.1629 - val_accuracy: 0.8258 - val_loss: 0.3975 - val_mae: 6.0269 - val_mse: 50.2926\n",
            "Epoch 160/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8427 - loss: 0.3585 - mae: 5.8996 - mse: 48.8093 - val_accuracy: 0.8170 - val_loss: 0.4085 - val_mae: 6.0269 - val_mse: 50.2924\n",
            "Epoch 161/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8371 - loss: 0.3691 - mae: 5.9762 - mse: 49.7986 - val_accuracy: 0.8273 - val_loss: 0.3751 - val_mae: 6.0269 - val_mse: 50.2931\n",
            "Epoch 162/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8344 - loss: 0.3810 - mae: 5.9610 - mse: 49.7874 - val_accuracy: 0.8322 - val_loss: 0.3792 - val_mae: 6.0269 - val_mse: 50.2934\n",
            "Epoch 163/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8383 - loss: 0.3718 - mae: 5.9393 - mse: 49.0021 - val_accuracy: 0.8273 - val_loss: 0.3979 - val_mae: 6.0269 - val_mse: 50.2940\n",
            "Epoch 164/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8351 - loss: 0.3810 - mae: 5.8983 - mse: 48.9050 - val_accuracy: 0.8205 - val_loss: 0.3974 - val_mae: 6.0269 - val_mse: 50.2944\n",
            "Epoch 165/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8461 - loss: 0.3686 - mae: 5.9154 - mse: 49.0116 - val_accuracy: 0.8263 - val_loss: 0.3828 - val_mae: 6.0269 - val_mse: 50.2940\n",
            "Epoch 166/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.3602 - mae: 5.8836 - mse: 48.7846 - val_accuracy: 0.8312 - val_loss: 0.3889 - val_mae: 6.0269 - val_mse: 50.2935\n",
            "Epoch 167/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8427 - loss: 0.3618 - mae: 5.9299 - mse: 49.1664 - val_accuracy: 0.8273 - val_loss: 0.3787 - val_mae: 6.0269 - val_mse: 50.2938\n",
            "Epoch 168/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 0.3736 - mae: 5.9233 - mse: 49.1615 - val_accuracy: 0.8175 - val_loss: 0.4085 - val_mae: 6.0269 - val_mse: 50.2939\n",
            "Epoch 169/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8394 - loss: 0.3797 - mae: 5.9081 - mse: 49.0345 - val_accuracy: 0.8126 - val_loss: 0.4032 - val_mae: 6.0269 - val_mse: 50.2933\n",
            "Epoch 170/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.3688 - mae: 5.9494 - mse: 49.2058 - val_accuracy: 0.8234 - val_loss: 0.4079 - val_mae: 6.0269 - val_mse: 50.2929\n",
            "Epoch 171/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.3802 - mae: 5.8854 - mse: 48.6335 - val_accuracy: 0.8200 - val_loss: 0.4196 - val_mae: 6.0269 - val_mse: 50.2929\n",
            "Epoch 172/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8373 - loss: 0.3735 - mae: 5.9242 - mse: 49.3398 - val_accuracy: 0.8249 - val_loss: 0.3887 - val_mae: 6.0269 - val_mse: 50.2938\n",
            "Epoch 173/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.3664 - mae: 5.9308 - mse: 49.2588 - val_accuracy: 0.8249 - val_loss: 0.3800 - val_mae: 6.0269 - val_mse: 50.2929\n",
            "Epoch 174/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 0.3718 - mae: 5.9562 - mse: 49.5024 - val_accuracy: 0.8160 - val_loss: 0.4002 - val_mae: 6.0269 - val_mse: 50.2934\n",
            "Epoch 175/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8434 - loss: 0.3664 - mae: 5.9060 - mse: 48.9722 - val_accuracy: 0.8307 - val_loss: 0.3728 - val_mae: 6.0269 - val_mse: 50.2929\n",
            "Epoch 176/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8385 - loss: 0.3709 - mae: 5.9075 - mse: 48.9259 - val_accuracy: 0.8244 - val_loss: 0.3778 - val_mae: 6.0269 - val_mse: 50.2936\n",
            "Epoch 177/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8435 - loss: 0.3595 - mae: 5.9571 - mse: 49.4707 - val_accuracy: 0.8229 - val_loss: 0.3866 - val_mae: 6.0269 - val_mse: 50.2919\n",
            "Epoch 178/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8453 - loss: 0.3593 - mae: 5.9704 - mse: 49.7011 - val_accuracy: 0.8341 - val_loss: 0.3722 - val_mae: 6.0269 - val_mse: 50.2933\n",
            "Epoch 179/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 0.3843 - mae: 5.9683 - mse: 49.6667 - val_accuracy: 0.8244 - val_loss: 0.3790 - val_mae: 6.0269 - val_mse: 50.2940\n",
            "Epoch 180/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.3667 - mae: 5.9307 - mse: 49.3590 - val_accuracy: 0.8278 - val_loss: 0.3748 - val_mae: 6.0269 - val_mse: 50.2942\n",
            "Epoch 181/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.3478 - mae: 5.9167 - mse: 49.0567 - val_accuracy: 0.8195 - val_loss: 0.3914 - val_mae: 6.0269 - val_mse: 50.2938\n",
            "Epoch 182/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8483 - loss: 0.3599 - mae: 5.9153 - mse: 49.1216 - val_accuracy: 0.8214 - val_loss: 0.3923 - val_mae: 6.0269 - val_mse: 50.2930\n",
            "Epoch 183/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8448 - loss: 0.3602 - mae: 5.9244 - mse: 49.1902 - val_accuracy: 0.8229 - val_loss: 0.4029 - val_mae: 6.0269 - val_mse: 50.2938\n",
            "Epoch 184/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8331 - loss: 0.3795 - mae: 5.9373 - mse: 49.2642 - val_accuracy: 0.8312 - val_loss: 0.3797 - val_mae: 6.0269 - val_mse: 50.2943\n",
            "Epoch 185/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8505 - loss: 0.3559 - mae: 5.9477 - mse: 49.5261 - val_accuracy: 0.8200 - val_loss: 0.4042 - val_mae: 6.0269 - val_mse: 50.2935\n",
            "Epoch 186/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8463 - loss: 0.3504 - mae: 5.9355 - mse: 49.1245 - val_accuracy: 0.8273 - val_loss: 0.4113 - val_mae: 6.0269 - val_mse: 50.2935\n",
            "Epoch 187/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.3672 - mae: 5.9542 - mse: 49.5504 - val_accuracy: 0.8253 - val_loss: 0.3804 - val_mae: 6.0269 - val_mse: 50.2931\n",
            "Epoch 188/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8480 - loss: 0.3530 - mae: 5.9529 - mse: 49.6262 - val_accuracy: 0.8249 - val_loss: 0.3854 - val_mae: 6.0269 - val_mse: 50.2934\n",
            "Epoch 189/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8402 - loss: 0.3670 - mae: 5.9227 - mse: 49.1695 - val_accuracy: 0.8200 - val_loss: 0.4021 - val_mae: 6.0269 - val_mse: 50.2937\n",
            "Epoch 190/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 0.3723 - mae: 5.9290 - mse: 49.0880 - val_accuracy: 0.7911 - val_loss: 0.4751 - val_mae: 6.0269 - val_mse: 50.2931\n",
            "Epoch 191/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8203 - loss: 0.4096 - mae: 5.9180 - mse: 49.0012 - val_accuracy: 0.8302 - val_loss: 0.3781 - val_mae: 6.0269 - val_mse: 50.2937\n",
            "Epoch 192/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8496 - loss: 0.3465 - mae: 5.9206 - mse: 49.0264 - val_accuracy: 0.8214 - val_loss: 0.4012 - val_mae: 6.0269 - val_mse: 50.2944\n",
            "Epoch 193/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.3682 - mae: 5.9628 - mse: 49.5814 - val_accuracy: 0.8214 - val_loss: 0.3899 - val_mae: 6.0269 - val_mse: 50.2932\n",
            "Epoch 194/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.3595 - mae: 5.9583 - mse: 49.5882 - val_accuracy: 0.8293 - val_loss: 0.3786 - val_mae: 6.0269 - val_mse: 50.2938\n",
            "Epoch 195/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.3591 - mae: 5.9596 - mse: 49.6165 - val_accuracy: 0.8244 - val_loss: 0.3846 - val_mae: 6.0269 - val_mse: 50.2943\n",
            "Epoch 196/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 0.3708 - mae: 5.9113 - mse: 48.9132 - val_accuracy: 0.8249 - val_loss: 0.3805 - val_mae: 6.0269 - val_mse: 50.2930\n",
            "Epoch 197/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.3470 - mae: 5.8491 - mse: 48.3271 - val_accuracy: 0.8195 - val_loss: 0.3994 - val_mae: 6.0269 - val_mse: 50.2938\n",
            "Epoch 198/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8357 - loss: 0.3801 - mae: 5.9409 - mse: 49.3376 - val_accuracy: 0.8341 - val_loss: 0.3768 - val_mae: 6.0269 - val_mse: 50.2939\n",
            "Epoch 199/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8450 - loss: 0.3554 - mae: 5.8993 - mse: 48.7503 - val_accuracy: 0.8234 - val_loss: 0.3930 - val_mae: 6.0269 - val_mse: 50.2940\n",
            "Epoch 200/200\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8435 - loss: 0.3547 - mae: 5.9109 - mse: 49.1833 - val_accuracy: 0.8332 - val_loss: 0.3677 - val_mae: 6.0269 - val_mse: 50.2951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_targets = df['Target'].unique().tolist()\n",
        "unique_targets.sort()\n",
        "\n",
        "print(\"Unique Targets:\")\n",
        "for target in unique_targets:\n",
        "    print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbuMV8Tq9N_u",
        "outputId": "035a297b-88b5-4730-c4da-75427fcf022e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Targets:\n",
            "Cystic Fibrosis-Related Diabetes (CFRD)\n",
            "Gestational Diabetes\n",
            "LADA\n",
            "MODY\n",
            "Neonatal Diabetes Mellitus (NDM)\n",
            "Prediabetic\n",
            "Secondary Diabetes\n",
            "Steroid-Induced Diabetes\n",
            "Type 1 Diabetes\n",
            "Type 2 Diabetes\n",
            "Type 3c Diabetes (Pancreatogenic Diabetes)\n",
            "Wolcott-Rallison Syndrome\n",
            "Wolfram Syndrome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, mae, mse = sulthan.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "\n",
        "y_pred = sulthan.predict(X_test)\n",
        "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
        "y_pred_probs = np.max(y_pred, axis=1)\n",
        "\n",
        "print(\"\\nExample Predictions:\")\n",
        "for i in range(20):\n",
        "    predicted_class_name = unique_targets[y_pred_classes[i]]\n",
        "    actual_class_name = unique_targets[y_test.iloc[i]]\n",
        "    print(f\"Sample {i+1}: Predicted Class - {predicted_class_name} ({y_pred_classes[i]}), Actual Class - {actual_class_name} ({y_test.iloc[i]}), Probability - {y_pred_probs[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYLhmEJzFHWM",
        "outputId": "112fe031-f329-46f8-d38c-36d64c4969bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.4120\n",
            "Test Accuracy: 0.8318\n",
            "Test MAE: 5.9542\n",
            "Test MSE: 49.0030\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\n",
            "Example Predictions:\n",
            "Sample 1: Predicted Class - Wolfram Syndrome (12), Actual Class - Wolfram Syndrome (12), Probability - 0.8343\n",
            "Sample 2: Predicted Class - Prediabetic (5), Actual Class - Prediabetic (5), Probability - 0.9650\n",
            "Sample 3: Predicted Class - Wolcott-Rallison Syndrome (11), Actual Class - Wolcott-Rallison Syndrome (11), Probability - 0.9999\n",
            "Sample 4: Predicted Class - Type 3c Diabetes (Pancreatogenic Diabetes) (10), Actual Class - Type 3c Diabetes (Pancreatogenic Diabetes) (10), Probability - 0.8269\n",
            "Sample 5: Predicted Class - Type 2 Diabetes (9), Actual Class - Type 2 Diabetes (9), Probability - 0.9986\n",
            "Sample 6: Predicted Class - Type 1 Diabetes (8), Actual Class - Type 1 Diabetes (8), Probability - 1.0000\n",
            "Sample 7: Predicted Class - Secondary Diabetes (6), Actual Class - Secondary Diabetes (6), Probability - 0.9998\n",
            "Sample 8: Predicted Class - MODY (3), Actual Class - Type 1 Diabetes (8), Probability - 0.6482\n",
            "Sample 9: Predicted Class - Gestational Diabetes (1), Actual Class - Prediabetic (5), Probability - 0.7853\n",
            "Sample 10: Predicted Class - Wolcott-Rallison Syndrome (11), Actual Class - Wolcott-Rallison Syndrome (11), Probability - 0.9313\n",
            "Sample 11: Predicted Class - Type 2 Diabetes (9), Actual Class - Type 2 Diabetes (9), Probability - 0.8021\n",
            "Sample 12: Predicted Class - Type 3c Diabetes (Pancreatogenic Diabetes) (10), Actual Class - Type 3c Diabetes (Pancreatogenic Diabetes) (10), Probability - 0.8637\n",
            "Sample 13: Predicted Class - Steroid-Induced Diabetes (7), Actual Class - Steroid-Induced Diabetes (7), Probability - 0.9238\n",
            "Sample 14: Predicted Class - MODY (3), Actual Class - MODY (3), Probability - 0.8946\n",
            "Sample 15: Predicted Class - MODY (3), Actual Class - MODY (3), Probability - 0.9359\n",
            "Sample 16: Predicted Class - Type 3c Diabetes (Pancreatogenic Diabetes) (10), Actual Class - Type 3c Diabetes (Pancreatogenic Diabetes) (10), Probability - 0.6492\n",
            "Sample 17: Predicted Class - LADA (2), Actual Class - LADA (2), Probability - 1.0000\n",
            "Sample 18: Predicted Class - Type 2 Diabetes (9), Actual Class - Type 2 Diabetes (9), Probability - 0.9971\n",
            "Sample 19: Predicted Class - MODY (3), Actual Class - MODY (3), Probability - 0.8920\n",
            "Sample 20: Predicted Class - Secondary Diabetes (6), Actual Class - Secondary Diabetes (6), Probability - 0.9719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sulthan.save(\"sulthan_cnn_models.keras\")"
      ],
      "metadata": {
        "id": "jAKxHeZ6FNuR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('unique_targets.txt', 'w') as f:\n",
        "    for target in unique_targets:\n",
        "        f.write(f\"{target}\\n\")"
      ],
      "metadata": {
        "id": "BJQqk1N__Z56"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}